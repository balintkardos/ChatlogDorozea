{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tv7 = \"dorozeaCheer dorozeaSpymain dorozeaDoroyeti dorozeaHELLO dorozeaDoroMAD dorozeaDoroHuge dorozeaLOVE dorozeaHey dorozeaDoroScared dorozeaWar dorozeaHUH dorozeaChad dorozeaSlam dorozeaDoropog dorozeaDoroMock dorozeaTouchingyou\"\n",
    "word_list = tv7.split(' ')\n",
    "tv72 = \"dorozeaAAAA dorozeaPog dorozeaDoroEvil dorozeaOmg dorozeaSignOff dorozeaDoroPogShake dorozeaAlert dorozeaTweak dorozeaGG dorozeaSCHIZO dorozeaUH dorozeaUWU dorozeaStare\"\n",
    "tv7_list2 = tv72.split(' ')\n",
    "\n",
    "merged_list = list(set(word_list + tv7_list2))\n",
    "\n",
    "merged_list = list(filter(None, merged_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of filenames from the configuration file\n",
    "with open('file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "# Iterate over each specified file\n",
    "for file in file_names:\n",
    "    full_path = \"data\\\\\"+file\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message,stream_count])\n",
    "    stream_count = stream_count + 1\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\",\"stream\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_word_counts(data, merged_list):\n",
    "    # Convert date once at the start\n",
    "    data['date'] = pd.to_datetime(data['date']).dt.date\n",
    "    \n",
    "    # Filter null streams\n",
    "    data = data[data['stream'].notnull()]\n",
    "    \n",
    "    # Pre-split all messages into words (do this once instead of repeatedly)\n",
    "    split_messages = data['message'].str.split(' ')\n",
    "    \n",
    "    # Create a dictionary to store word counts by date\n",
    "    word_counts_dict = {}\n",
    "    \n",
    "    # Process each message's words in bulk\n",
    "    for date, words in zip(data['date'], split_messages):\n",
    "        # Convert words to set for faster lookup\n",
    "        words_set = set(words)\n",
    "        # Check which target words appear in this message\n",
    "        matched_words = [word for word in merged_list if word in words_set]\n",
    "        # Update counts for each matched word\n",
    "        for word in matched_words:\n",
    "            if word not in word_counts_dict:\n",
    "                word_counts_dict[word] = Counter()\n",
    "            word_counts_dict[word][date] += 1\n",
    "    \n",
    "    # Convert the nested dictionary to a dataframe\n",
    "    rows = []\n",
    "    for word, date_counts in word_counts_dict.items():\n",
    "        for date, count in date_counts.items():\n",
    "            rows.append({\n",
    "                'date': date,\n",
    "                'word': word,\n",
    "                'count': count\n",
    "            })\n",
    "    \n",
    "    final_data = pd.DataFrame(rows)\n",
    "    \n",
    "    # Sort if there are any results\n",
    "    if not final_data.empty:\n",
    "        final_data = final_data.sort_values(by=['word', 'date']).reset_index(drop=True)\n",
    "    \n",
    "    return final_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_data = optimize_word_counts(data, merged_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date  dorozeaAAAA  dorozeaAlert  dorozeaChad  dorozeaCheer  \\\n",
      "0    2024-05-01          0.0           0.0          0.0           0.0   \n",
      "1    2024-05-02          0.0           0.0          0.0           0.0   \n",
      "2    2024-05-03          0.0           0.0          0.0           0.0   \n",
      "3    2024-05-04          0.0           0.0          0.0           0.0   \n",
      "4    2024-05-05          0.0           0.0          0.0           0.0   \n",
      "..          ...          ...           ...          ...           ...   \n",
      "213  2025-01-16          2.0           7.0          3.0           1.0   \n",
      "214  2025-01-17          4.0           0.0          1.0           2.0   \n",
      "215  2025-01-18          1.0          12.0          1.0           1.0   \n",
      "216  2025-01-19          2.0          11.0          3.0           1.0   \n",
      "217  2025-01-20          0.0           5.0          3.0           0.0   \n",
      "\n",
      "     dorozeaDoroEvil  dorozeaDoroHuge  dorozeaDoroMAD  dorozeaDoroMock  \\\n",
      "0                0.0              0.0             0.0              1.0   \n",
      "1                0.0              0.0             0.0              0.0   \n",
      "2                0.0              0.0             0.0              0.0   \n",
      "3                0.0              0.0             0.0              0.0   \n",
      "4                1.0              0.0             1.0              0.0   \n",
      "..               ...              ...             ...              ...   \n",
      "213              3.0              0.0             1.0              5.0   \n",
      "214              9.0              1.0             3.0              6.0   \n",
      "215              6.0              2.0             1.0              2.0   \n",
      "216              2.0              2.0             0.0             10.0   \n",
      "217              2.0              0.0             2.0              2.0   \n",
      "\n",
      "     dorozeaDoroPogShake  ...  dorozeaSCHIZO  dorozeaSignOff  dorozeaSlam  \\\n",
      "0                    2.0  ...            0.0             0.0          0.0   \n",
      "1                    0.0  ...            0.0             0.0          0.0   \n",
      "2                    1.0  ...            0.0             0.0          0.0   \n",
      "3                    1.0  ...            0.0             0.0          0.0   \n",
      "4                    1.0  ...            0.0             0.0          0.0   \n",
      "..                   ...  ...            ...             ...          ...   \n",
      "213                  4.0  ...            2.0             1.0          1.0   \n",
      "214                 19.0  ...            1.0             2.0          4.0   \n",
      "215                  0.0  ...            0.0             2.0          7.0   \n",
      "216                 15.0  ...            0.0             3.0          5.0   \n",
      "217                  6.0  ...            0.0             1.0          7.0   \n",
      "\n",
      "     dorozeaSpymain  dorozeaStare  dorozeaTouchingyou  dorozeaTweak  \\\n",
      "0               1.0           0.0                 0.0           0.0   \n",
      "1               0.0           0.0                 0.0           0.0   \n",
      "2               0.0           0.0                 0.0           0.0   \n",
      "3               0.0           0.0                 0.0           0.0   \n",
      "4               2.0           0.0                 0.0           0.0   \n",
      "..              ...           ...                 ...           ...   \n",
      "213             0.0           0.0                 1.0           6.0   \n",
      "214             0.0           0.0                 2.0           7.0   \n",
      "215             0.0           0.0                 2.0           7.0   \n",
      "216             0.0           0.0                 1.0           3.0   \n",
      "217             0.0           0.0                 2.0           4.0   \n",
      "\n",
      "     dorozeaUH  dorozeaUWU  dorozeaWar  \n",
      "0          0.0         0.0         0.0  \n",
      "1          0.0         0.0         0.0  \n",
      "2          0.0         0.0         0.0  \n",
      "3          0.0         0.0         0.0  \n",
      "4          0.0         0.0         0.0  \n",
      "..         ...         ...         ...  \n",
      "213        1.0         0.0         9.0  \n",
      "214        0.0         0.0        21.0  \n",
      "215        0.0         0.0         4.0  \n",
      "216        2.0         1.0         4.0  \n",
      "217        0.0         0.0         3.0  \n",
      "\n",
      "[218 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# Pivot the data to have words as columns and dates as rows\n",
    "pivot_data = final_data.pivot_table(\n",
    "    index='date',    # Rows: dates\n",
    "    columns='word',  # Columns: words\n",
    "    values='count',  # Values: word counts\n",
    "    fill_value=0     # Fill missing values with 0\n",
    ").reset_index()\n",
    "\n",
    "# Flatten the columns if needed (e.g., remove multi-index)\n",
    "pivot_data.columns.name = None  # Remove the name of columns\n",
    "pivot_data = pivot_data.rename_axis(None, axis=1)\n",
    "\n",
    "# Display the reshaped data\n",
    "print(pivot_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total usage of each word:\n",
      "dorozeaGG                 6.0\n",
      "dorozeaStare             19.0\n",
      "dorozeaUH                21.0\n",
      "dorozeaSCHIZO            29.0\n",
      "dorozeaSpymain           53.0\n",
      "dorozeaUWU               68.0\n",
      "dorozeaDoroyeti          92.0\n",
      "dorozeaWar              117.0\n",
      "dorozeaDoroHuge         121.0\n",
      "dorozeaCheer            152.0\n",
      "dorozeaAAAA             197.0\n",
      "dorozeaDoroMAD          202.0\n",
      "dorozeaChad             209.0\n",
      "dorozeaPog              238.0\n",
      "dorozeaHELLO            251.0\n",
      "dorozeaDoroScared       274.0\n",
      "dorozeaTweak            326.0\n",
      "dorozeaOmg              369.0\n",
      "dorozeaTouchingyou      372.0\n",
      "dorozeaDoroMock         462.0\n",
      "dorozeaSignOff          465.0\n",
      "dorozeaAlert            473.0\n",
      "dorozeaDoroEvil         518.0\n",
      "dorozeaLOVE             567.0\n",
      "dorozeaHUH              583.0\n",
      "dorozeaHey              822.0\n",
      "dorozeaDoroPogShake     856.0\n",
      "dorozeaSlam            1192.0\n",
      "dtype: float64\n",
      "\n",
      "Words barely used (threshold <= 1):\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "threshold = 1\n",
    "# Calculate the total usage for each word\n",
    "total_usage = pivot_data.drop(columns=['date']).sum().sort_values()\n",
    "\n",
    "# Find words with the lowest usage\n",
    "barely_used_words = total_usage[total_usage <= threshold].index.tolist()\n",
    "\n",
    "# Display results\n",
    "print(\"Total usage of each word:\")\n",
    "print(total_usage)\n",
    "\n",
    "print(\"\\nWords barely used (threshold <= {}):\".format(threshold))\n",
    "print(barely_used_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data_cleaned = pivot_data.drop(columns=barely_used_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data_cleaned = pivot_data_cleaned.set_index('date').cumsum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data_cleaned_transposed = pivot_data_cleaned.T\n",
    "pivot_data_cleaned_transposed = pivot_data_cleaned.T.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pivot_data_cleaned_transposed.to_excel('your_excel_file.xlsx', sheet_name='Pivot Table')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
