{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24087cdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total messages: 1768831\n",
      "Unique users: 61957\n",
      "Streams processed: 319\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import os\n",
    "import logging\n",
    "from collections import defaultdict\n",
    "from typing import List, Dict, Set, Tuple\n",
    "\n",
    "# Set up logging\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    filename='chat_processing.log'\n",
    ")\n",
    "\n",
    "def read_file_list(config_path: str) -> List[str]:\n",
    "    \"\"\"\n",
    "    Read the list of filenames from the configuration file.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path to the configuration file\n",
    "        \n",
    "    Returns:\n",
    "        List of filenames\n",
    "    \"\"\"\n",
    "    try:\n",
    "        with open(config_path, 'r', encoding='utf-8') as config_file:\n",
    "            return config_file.read().splitlines()\n",
    "    except FileNotFoundError:\n",
    "        logging.error(f\"Configuration file not found: {config_path}\")\n",
    "        return []\n",
    "    except Exception as e:\n",
    "        logging.error(f\"Error reading configuration file: {e}\")\n",
    "        return []\n",
    "\n",
    "def parse_chat_files(file_names: List[str], base_path: str = \"../../data/\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Parse multiple chat log files and combine the data.\n",
    "    \n",
    "    Args:\n",
    "        file_names: List of files to process\n",
    "        base_path: Base directory for the files\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame containing parsed chat data\n",
    "    \"\"\"\n",
    "    pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "    datalist = []\n",
    "    \n",
    "    for stream_count, file in enumerate(file_names):\n",
    "        full_path = os.path.join(base_path, file)\n",
    "        try:\n",
    "            with open(full_path, 'r', encoding='utf-8') as f:\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    match = re.match(pattern, line.strip())\n",
    "                    if match:\n",
    "                        date, user, message = match.groups()\n",
    "                        datalist.append([date, user, message, stream_count])\n",
    "                    else:\n",
    "                        logging.warning(f\"Line doesn't match pattern: {line.strip()[:50]}...\")\n",
    "            logging.info(f\"Successfully processed file: {file}\")\n",
    "        except FileNotFoundError:\n",
    "            logging.error(f\"File not found: {full_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error processing file {full_path}: {e}\")\n",
    "    \n",
    "    if not datalist:\n",
    "        logging.warning(\"No data was parsed from the files\")\n",
    "        return pd.DataFrame(columns=[\"date\", \"user\", \"message\", \"stream\"])\n",
    "    \n",
    "    return pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\", \"stream\"])\n",
    "\n",
    "def load_username_mappings(mapping_path: str = None) -> Dict[str, str]:\n",
    "    \"\"\"\n",
    "    Load manual username mappings from a file or return default mappings.\n",
    "    \n",
    "    Args:\n",
    "        mapping_path: Path to the username mapping file (optional)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary mapping from original usernames to canonical usernames\n",
    "    \"\"\"\n",
    "    default_mappings = {\n",
    "        \"Banties1g\": \"banties_x\",\n",
    "        \"banties1g\": \"banties_x\",\n",
    "        \"fyodor_m_d1821\": \"fyredoor4\",\n",
    "        \"chili_poe\": \"chili_con_bacon\",\n",
    "        \"Wirelesss_\": \"W1r3lesss\",\n",
    "        \"treklul\": \"trek44_\",\n",
    "        \"ttrek_\": \"trek44_\",\n",
    "        \"TriplesingleJ\": \"TripleSingleJames\",\n",
    "        \"uuccugr\": \"uwu_cougar\"\n",
    "    }\n",
    "    \n",
    "    if mapping_path and os.path.exists(mapping_path):\n",
    "        try:\n",
    "            mappings = {}\n",
    "            with open(mapping_path, 'r', encoding='utf-8') as f:\n",
    "                for line in f:\n",
    "                    if ':' in line:\n",
    "                        original, canonical = line.strip().split(':', 1)\n",
    "                        mappings[original.strip()] = canonical.strip()\n",
    "            return mappings\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error loading username mappings: {e}\")\n",
    "            return default_mappings\n",
    "    \n",
    "    return default_mappings\n",
    "\n",
    "def find_username_variants(users: List[str]) -> Tuple[Dict[str, Set[str]], Dict[str, str]]:\n",
    "    \"\"\"\n",
    "    Find username variants with different capitalizations and create a mapping.\n",
    "    \n",
    "    Args:\n",
    "        users: List of usernames\n",
    "        \n",
    "    Returns:\n",
    "        Tuple containing:\n",
    "        - Dictionary mapping lowercase username to all variants\n",
    "        - Dictionary mapping each variant to its canonical form\n",
    "    \"\"\"\n",
    "    user_variants = defaultdict(set)\n",
    "    for user in users:\n",
    "        user_variants[user.lower()].add(user)\n",
    "    \n",
    "    # Find usernames with different capitalization\n",
    "    duplicate_users = {k: v for k, v in user_variants.items() if len(v) > 1}\n",
    "    \n",
    "    # Create a mapping from all variants to the canonical (sorted first) variant\n",
    "    variant_map = {}\n",
    "    for variants in duplicate_users.values():\n",
    "        sorted_variants = sorted(variants)\n",
    "        canonical = sorted_variants[0]\n",
    "        for v in variants:\n",
    "            variant_map[v] = canonical\n",
    "    \n",
    "    return duplicate_users, variant_map\n",
    "\n",
    "def replace_mentions(msg: str, variant_map: Dict[str, str]) -> str:\n",
    "    \"\"\"\n",
    "    Replace username mentions in messages with their canonical forms.\n",
    "    \n",
    "    Args:\n",
    "        msg: Message text\n",
    "        variant_map: Mapping from username variants to canonical forms\n",
    "        \n",
    "    Returns:\n",
    "        Updated message with standardized username mentions\n",
    "    \"\"\"\n",
    "    for v, canonical in variant_map.items():\n",
    "        # Replace only whole word matches (case-sensitive)\n",
    "        msg = re.sub(rf'\\b{re.escape(v)}\\b', canonical, msg)\n",
    "    return msg\n",
    "\n",
    "def standardize_usernames(data: pd.DataFrame, manual_mappings: Dict[str, str] = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Standardize usernames in the dataset.\n",
    "    \n",
    "    Args:\n",
    "        data: DataFrame containing chat data\n",
    "        manual_mappings: Dictionary of manual username mappings\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with standardized usernames\n",
    "    \"\"\"\n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = data.copy()\n",
    "    \n",
    "    # Apply manual mappings first\n",
    "    if manual_mappings:\n",
    "        for original, canonical in manual_mappings.items():\n",
    "            df.loc[df['user'] == original, 'user'] = canonical\n",
    "    \n",
    "    # Find and apply capitalization variants\n",
    "    unique_users = df['user'].unique()\n",
    "    duplicate_users, variant_map = find_username_variants(unique_users)\n",
    "    \n",
    "    # Log the found variants\n",
    "    for lower, variants in duplicate_users.items():\n",
    "        logging.info(f\"Found username variants for {lower}: {sorted(variants)}\")\n",
    "    \n",
    "    # Replace usernames in 'user' column\n",
    "    df['user'] = df['user'].apply(lambda u: variant_map.get(u, u))\n",
    "    \n",
    "    # Replace mentions in 'message' column\n",
    "    df['message'] = df['message'].apply(lambda msg: replace_mentions(msg, variant_map))\n",
    "    \n",
    "    return df\n",
    "\n",
    "def process_chat_logs(config_path: str = '../../file_list.txt', \n",
    "                      mapping_path: str = None,\n",
    "                      output_path: str = None) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Main function to process chat logs.\n",
    "    \n",
    "    Args:\n",
    "        config_path: Path to the file listing chat logs\n",
    "        mapping_path: Path to the username mapping file (optional)\n",
    "        output_path: Path to save the processed data (optional)\n",
    "        \n",
    "    Returns:\n",
    "        DataFrame with processed chat data\n",
    "    \"\"\"\n",
    "    logging.info(\"Starting chat log processing\")\n",
    "    \n",
    "    # Read file list\n",
    "    file_names = read_file_list(config_path)\n",
    "    if not file_names:\n",
    "        logging.error(\"No files to process. Exiting.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    logging.info(f\"Found {len(file_names)} files to process\")\n",
    "    \n",
    "    # Parse chat files\n",
    "    data = parse_chat_files(file_names)\n",
    "    if data.empty:\n",
    "        logging.error(\"No data was parsed. Exiting.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    logging.info(f\"Parsed {len(data)} chat messages\")\n",
    "    \n",
    "    # Load username mappings\n",
    "    manual_mappings = load_username_mappings(mapping_path)\n",
    "    \n",
    "    # Standardize usernames\n",
    "    processed_data = standardize_usernames(data, manual_mappings)\n",
    "    \n",
    "    # Save processed data if requested\n",
    "    if output_path:\n",
    "        try:\n",
    "            #processed_data.to_csv(output_path, index=False)\n",
    "            logging.info(f\"Saved processed data to {output_path}\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving processed data: {e}\")\n",
    "    \n",
    "    logging.info(\"Chat log processing completed\")\n",
    "    return processed_data\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example usage\n",
    "    df = process_chat_logs(\n",
    "        config_path='../../file_list.txt',\n",
    "        output_path='processed_chat_data.csv'\n",
    "    )\n",
    "    \n",
    "    # Print some statistics\n",
    "    print(f\"Total messages: {len(df)}\")\n",
    "    print(f\"Unique users: {df['user'].nunique()}\")\n",
    "    print(f\"Streams processed: {df['stream'].nunique()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
