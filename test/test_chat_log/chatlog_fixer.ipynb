{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b591e4a",
   "metadata": {},
   "source": [
    "download from here: https://tv.supa.sh/logs?c=dorozea\n",
    "\n",
    "0. only need data when stream was on\n",
    "1. remove all the deleted messages\n",
    "    if deleted only new line and his message  up\n",
    "2. remove the time outs and the banned persons\n",
    "3. remove #dorozea in the line\n",
    "4. fix the date \n",
    "5. fix the capitalization \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea1c15d",
   "metadata": {},
   "source": [
    "fixed: 04.24.25 only first 10 line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db70e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the file and clean the data\n",
    "with open('testclean.txt', 'r', encoding='utf-8') as file:\n",
    "    lines = file.readlines()\n",
    "\n",
    "# Process each line\n",
    "cleaned_lines = []\n",
    "for line in lines:\n",
    "    # Remove '#dorozea' and add 'UTC' to the timestamp\n",
    "    if line.strip():  # Skip empty lines\n",
    "        cleaned_line = line.replace('#dorozea ', '', 1).replace(']', ' UTC]', 1)\n",
    "        cleaned_lines.append(cleaned_line)\n",
    "\n",
    "# Save the cleaned data back to a file or print it\n",
    "with open('cleaned_testclean.txt', 'w', encoding='utf-8') as file:\n",
    "    file.writelines(cleaned_lines)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5439555d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e7c10795",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of filenames from the configuration file\n",
    "with open('../../file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "# Iterate over each specified file\n",
    "for file in file_names:\n",
    "    full_path = f\"../../data/{file}\"\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message,stream_count])\n",
    "    stream_count = stream_count + 1\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\",\"stream\"])\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\",\"stream\"])\n",
    "\n",
    "data[\"user\"] = data[\"user\"].replace(\"Banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"fyodor_m_d1821\", \"fyredoor4\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"chili_poe\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"Wirelesss_\", \"W1r3lesss\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"treklul\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"ttrek_\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"TriplesingleJ\", \"TripleSingleJames\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"uuccugr\", \"uwu_cougar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dbb5de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping of lowercase usernames to properly capitalized usernames\n",
    "user_mapping = {user.lower(): user for user in data['user'].unique()}\n",
    "\n",
    "# Update cleaned_lines with capitalized usernames while preserving line fragmentation\n",
    "updated_lines = []\n",
    "for line in cleaned_lines:\n",
    "    match = re.match(r'\\[(.*?)\\] (.*?): (.*)', line)\n",
    "    if match:\n",
    "        date, user, message = match.groups()\n",
    "        capitalized_user = user_mapping.get(user.lower(), user)  # Use capitalized version if available\n",
    "        updated_line = f\"[{date}] {capitalized_user}: {message}\"\n",
    "        if line.endswith('\\n'):  # Preserve the newline character\n",
    "            updated_line += '\\n'\n",
    "        updated_lines.append(updated_line)\n",
    "\n",
    "# Save the updated lines to a file\n",
    "with open('updated_cleaned_lines.txt', 'w', encoding='utf-8') as file:\n",
    "    file.writelines(updated_lines)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
