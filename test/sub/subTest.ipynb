{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1c6c9e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pytz\n",
    "import re\n",
    "\n",
    "\n",
    "# Read the list of filenames from the configuration file\n",
    "with open('../../file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "# Iterate over each specified file\n",
    "for file in file_names:\n",
    "    full_path = \"../../data\\\\\"+file\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message,stream_count])\n",
    "    stream_count = stream_count + 1\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\",\"stream\"])\n",
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "def convert_utc_to_cet(df, date_column='date'):\n",
    "    \"\"\"\n",
    "    Convert UTC timestamps to Central European Time (CET/CEST) with proper DST handling\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the date column\n",
    "    date_column (str): Name of the column containing UTC timestamps\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with converted timestamps\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure timestamps are UTC aware\n",
    "    if df[date_column].dt.tz is None:\n",
    "        df[date_column] = df[date_column].dt.tz_localize('UTC')\n",
    "    elif df[date_column].dt.tz != pytz.UTC:\n",
    "        df[date_column] = df[date_column].dt.tz_convert('UTC')\n",
    "    \n",
    "    # Convert to CET/CEST (Europe/Berlin includes proper DST handling)\n",
    "    df[date_column] = df[date_column].dt.tz_convert('Europe/Berlin')\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = convert_utc_to_cet(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ad1c8cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_stream_stats(df):\n",
    "    \"\"\"\n",
    "    Parses chat data to extract subscription and gifting stats per stream.\n",
    "    \"\"\"\n",
    "    # 1. Filter for system messages where user name appears in message\n",
    "    # Use copy() to avoid SettingWithCopy warnings later\n",
    "    subData = df[df.apply(lambda row: str(row['user']).lower() in str(row['message']).lower(), axis=1)].copy()\n",
    "    \n",
    "    # 2. Exclude \"converted from\" messages\n",
    "    subData = subData[~subData['message'].str.contains(' converted from ', case=False, na=False)]\n",
    "    \n",
    "    # --- Initialize stream_stats ---\n",
    "    # We create a base dataframe with all unique streams found in the subset\n",
    "    unique_streams = subData['stream'].unique()\n",
    "    stream_stats = pd.DataFrame(unique_streams, columns=['stream'])\n",
    "\n",
    "    # --- Gifted Data Logic ---\n",
    "    giftedData = subData[subData['message'].str.contains(' sub ', case=False, na=False)]\n",
    "    \n",
    "    # Calculate unique gifters (This was a print statement in your code)\n",
    "    # We can add this to the stats if needed, or just calculate it globally\n",
    "    unique_gifter_count = giftedData['user'].nunique()\n",
    "    \n",
    "    # --- Gifter Logic (Batch Gifts) ---\n",
    "    gifterData = subData[subData['message'].str.contains(' is gifting ', case=False, na=False)].copy()\n",
    "    \n",
    "    # helper to safely extract numbers\n",
    "    def get_gift_amount(x):\n",
    "        search = re.search(r'gifting\\s(\\d+)', x)\n",
    "        return int(search.group(1)) if search else 0\n",
    "        \n",
    "    gifterData['gifts'] = gifterData['message'].apply(get_gift_amount)\n",
    "    gift_per_stream_2 = gifterData.groupby('stream')['gifts'].sum().reset_index(name='gift2')\n",
    "\n",
    "    # Merge batch gifts\n",
    "    stream_stats = pd.merge(stream_stats, gift_per_stream_2, on='stream', how='left')\n",
    "    stream_stats['gift2'] = stream_stats['gift2'].fillna(0)\n",
    "\n",
    "    # --- Unique Gifters per Stream ---\n",
    "    unique_users_per_stream = giftedData.groupby('stream')['user'].nunique().reset_index(name='gifter')\n",
    "    stream_stats = pd.merge(stream_stats, unique_users_per_stream, on='stream', how='left')\n",
    "    stream_stats['gifter'] = stream_stats['gifter'].fillna(0)\n",
    "\n",
    "    # --- Gift Count (Individual) ---\n",
    "    gift_per_stream = giftedData.groupby('stream')['user'].count().reset_index(name='gift')\n",
    "    stream_stats = pd.merge(stream_stats, gift_per_stream, on='stream', how='left')\n",
    "    stream_stats['gift'] = stream_stats['gift'].fillna(0)\n",
    "\n",
    "    # Max logic as per your script\n",
    "    stream_stats['gift'] = np.maximum(stream_stats['gift'], stream_stats['gift2'])\n",
    "\n",
    "    # --- Prime Logic ---\n",
    "    primeData = subData[subData['message'].str.contains('Prime', case=False, na=False)]\n",
    "    prime_per_stream = primeData.groupby('stream')['user'].count().reset_index(name='prime')\n",
    "    stream_stats = pd.merge(stream_stats, prime_per_stream, on='stream', how='left')\n",
    "    stream_stats['prime'] = stream_stats['prime'].fillna(0)\n",
    "\n",
    "    # --- True Sub (Tier) Logic ---\n",
    "    trueSub = subData[~subData['message'].str.contains('Prime', case=False, na=False)]\n",
    "    trueSub = trueSub[~trueSub['message'].str.contains('gifting', case=False, na=False)]\n",
    "    trueSub = trueSub[~trueSub['message'].str.contains('gifted', case=False, na=False)]\n",
    "    trueSub = trueSub[trueSub['message'].str.contains(' subscribed at ', case=False, na=False)]\n",
    "\n",
    "    for i in range(1, 4):\n",
    "        tier_name = f'Tier {i}'\n",
    "        col_name = f'tier{i}'\n",
    "        tier_data = trueSub[trueSub['message'].str.contains(tier_name, case=False, na=False)]\n",
    "        tier_counts = tier_data.groupby('stream')['user'].count().reset_index(name=col_name)\n",
    "        \n",
    "        stream_stats = pd.merge(stream_stats, tier_counts, on='stream', how='left')\n",
    "        stream_stats[col_name] = stream_stats[col_name].fillna(0)\n",
    "\n",
    "    return stream_stats, unique_gifter_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2e75f1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing Original Data...\n",
      "Processing Cleaned Data...\n",
      "\n",
      "=== TOTAL COUNTS COMPARISON ===\n",
      "  Metric  Original Total  Cleaned Total  Difference\n",
      "0  prime          5302.0         5282.0       -20.0\n",
      "1  tier1          4182.0         4134.0       -48.0\n",
      "2  tier2            42.0           42.0         0.0\n",
      "3  tier3           243.0          231.0       -12.0\n",
      "\n",
      "=== FOUND 68 STREAMS WITH DATA MISMATCHES ===\n",
      "     stream  prime_diff  tier1_diff  tier2_diff  tier3_diff\n",
      "10       10        -1.0         0.0         0.0         0.0\n",
      "39       39         0.0        -1.0         0.0         0.0\n",
      "48       48         0.0        -1.0         0.0         0.0\n",
      "61       61         0.0        -1.0         0.0         0.0\n",
      "71       71         0.0        -1.0         0.0         0.0\n",
      "..      ...         ...         ...         ...         ...\n",
      "498     498         0.0         0.0         0.0        -1.0\n",
      "504     504         0.0        -1.0         0.0         0.0\n",
      "505     505         0.0        -1.0         0.0         0.0\n",
      "507     507        -1.0         0.0         0.0         0.0\n",
      "508     508         0.0        -1.0         0.0         0.0\n",
      "\n",
      "[68 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# --- 1. Define the Cleaning Logic ---\n",
    "replacements = {\n",
    "    \"Banties1g\": \"banties_x\",\n",
    "    \"banties1g\": \"banties_x\",\n",
    "    \"chili_poe\": \"chili_con_bacon\",\n",
    "    \"CHILI_POE\": \"chili_con_bacon\",\n",
    "    \"chili_conbacon\": \"chili_con_bacon\",\n",
    "    \"Wirelesss_\": \"W1r3lesss\",\n",
    "    \"treklul\": \"trek44_\",\n",
    "    \"ttrek_\": \"trek44_\",\n",
    "    \"trek_x\": \"trek44_\",\n",
    "    \"TriplesingleJ\": \"TripleSingleJames\",\n",
    "    \"uuccugr\": \"uwu_cougar\",\n",
    "    \"uuccugr_\": \"uwu_cougar\",\n",
    "    \"StanIV4_\": \"stan_iv4\",\n",
    "    \"Muuskie2\": \"Muuskie\",\n",
    "    \"nishad_more1311\": \"nishad13\",\n",
    "    \"softarballt\": \"softarr\",\n",
    "    \"softarballtt23\": \"softarr\",\n",
    "    \"lajosbarnabas\": \"lajoss__\"\n",
    "}\n",
    "\n",
    "# --- 2. Create Cleaned Data ---\n",
    "clean_data = data.copy()\n",
    "clean_data[\"user\"] = clean_data[\"user\"].replace(replacements)\n",
    "\n",
    "# --- 3. Process Both Datasets ---\n",
    "# (Using the process_stream_stats function defined in the previous step)\n",
    "print(\"Processing Original Data...\")\n",
    "stats_orig, _ = process_stream_stats(data)\n",
    "\n",
    "print(\"Processing Cleaned Data...\")\n",
    "stats_clean, _ = process_stream_stats(clean_data)\n",
    "\n",
    "# --- 4. Merge and Compare Tiers/Prime Only ---\n",
    "# Merge on 'stream' to align the rows\n",
    "comparison = pd.merge(\n",
    "    stats_orig[['stream', 'prime', 'tier1', 'tier2', 'tier3']],\n",
    "    stats_clean[['stream', 'prime', 'tier1', 'tier2', 'tier3']],\n",
    "    on='stream',\n",
    "    suffixes=('_orig', '_clean'),\n",
    "    how='outer'\n",
    ").fillna(0)\n",
    "\n",
    "# Calculate Differences (Cleaned - Original)\n",
    "cols_to_compare = ['prime', 'tier1', 'tier2', 'tier3']\n",
    "\n",
    "for col in cols_to_compare:\n",
    "    # Calculate delta\n",
    "    comparison[f'{col}_diff'] = comparison[f'{col}_clean'] - comparison[f'{col}_orig']\n",
    "\n",
    "# --- 5. Display Results ---\n",
    "\n",
    "# A. Total Aggregate Counts (Did we lose or gain total subs?)\n",
    "print(\"\\n=== TOTAL COUNTS COMPARISON ===\")\n",
    "summary = pd.DataFrame({\n",
    "    'Metric': cols_to_compare,\n",
    "    'Original Total': [comparison[f'{c}_orig'].sum() for c in cols_to_compare],\n",
    "    'Cleaned Total': [comparison[f'{c}_clean'].sum() for c in cols_to_compare],\n",
    "    'Difference': [comparison[f'{c}_diff'].sum() for c in cols_to_compare]\n",
    "})\n",
    "print(summary)\n",
    "\n",
    "# B. Streams with Discrepancies\n",
    "# Show only streams where the numbers don't match\n",
    "diff_mask = (comparison['prime_diff'] != 0) | \\\n",
    "            (comparison['tier1_diff'] != 0) | \\\n",
    "            (comparison['tier2_diff'] != 0) | \\\n",
    "            (comparison['tier3_diff'] != 0)\n",
    "\n",
    "discrepancies = comparison[diff_mask].copy()\n",
    "\n",
    "if not discrepancies.empty:\n",
    "    print(f\"\\n=== FOUND {len(discrepancies)} STREAMS WITH DATA MISMATCHES ===\")\n",
    "    # Select relevant columns to display\n",
    "    display_cols = ['stream'] + [f'{c}_diff' for c in cols_to_compare]\n",
    "    print(discrepancies[display_cols])\n",
    "else:\n",
    "    print(\"\\n=== NO DATA LOSS DETECTED ===\")\n",
    "    print(\"The renaming of users did not affect the subscription counts.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
