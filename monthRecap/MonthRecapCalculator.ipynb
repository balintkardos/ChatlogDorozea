{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6a61989",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "import pytz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "58865add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the list of filenames from the configuration file\n",
    "with open('../file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "# Iterate over each specified file\n",
    "for file in file_names:\n",
    "    full_path = f\"../data/{file}\"\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message,stream_count])\n",
    "    stream_count = stream_count + 1\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\",\"stream\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "19eaac2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "data['date'] = pd.to_datetime(data['date'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55691696",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def convert_utc_to_cet(df, date_column='date'):\n",
    "    \"\"\"\n",
    "    Convert UTC timestamps to Central European Time (CET/CEST) with proper DST handling\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the date column\n",
    "    date_column (str): Name of the column containing UTC timestamps\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with converted timestamps\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure timestamps are UTC aware\n",
    "    if df[date_column].dt.tz is None:\n",
    "        df[date_column] = df[date_column].dt.tz_localize('UTC')\n",
    "    elif df[date_column].dt.tz != pytz.UTC:\n",
    "        df[date_column] = df[date_column].dt.tz_convert('UTC')\n",
    "    \n",
    "    # Convert to CET/CEST (Europe/Berlin includes proper DST handling)\n",
    "    df[date_column] = df[date_column].dt.tz_convert('Europe/Berlin')\n",
    "    \n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5700f0b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_utc_to_cet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3b966d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"user\"] = data[\"user\"].replace(\"Banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"chili_poe\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"CHILI_POE\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"chili_conbacon\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"Wirelesss_\", \"W1r3lesss\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"treklul\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"ttrek_\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"trek_x\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"TriplesingleJ\", \"TripleSingleJames\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"uuccugr\", \"uwu_cougar\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"uuccugr\", \"uuccugr_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"StanIV4_\", \"stan_iv4\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"Muuskie2\", \"Muuskie\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"nishad_more1311\", \"nishad13\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"softarballt\", \"softarr\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"softarballtt23\", \"softarr\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"bonkwiththefunk\", \"bonk67\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "71ae4b1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get all unique usernames\n",
    "unique_users = data['user'].unique()\n",
    "\n",
    "# Create a mapping from lowercase username to all variants\n",
    "\n",
    "user_variants = defaultdict(set)\n",
    "for user in unique_users:\n",
    "    user_variants[user.lower()].add(user)\n",
    "\n",
    "# Find usernames with different capitalization\n",
    "duplicate_users = {k: v for k, v in user_variants.items() if len(v) > 1}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "32df7453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from all variants to the canonical (sorted first) variant\n",
    "variant_map = {}\n",
    "for variants in duplicate_users.values():\n",
    "    sorted_variants = sorted(variants)\n",
    "    canonical = sorted_variants[0]\n",
    "    for v in variants:\n",
    "        variant_map[v] = canonical\n",
    "\n",
    "# Replace usernames in 'user' column\n",
    "data['user'] = data['user'].apply(lambda u: variant_map.get(u, u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4ae0e444",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total unique emotes: 1040\n"
     ]
    }
   ],
   "source": [
    "# 7tv list\n",
    "tv7_emotes = \"\"\"omeFaded nonono wideSpeedFear wideSpeedDesert SpeedOmg Disappointed ME? ome13 doroPfft CONFUSED doro52 wideSpeedConcerned doroBANGER doroVibe DoroBrainPLug NAHHHH intrigued oda WOOF BANG peepoFirework Gladge omeMoji SobBounce belka doroHips dorochan doroXi DOMEYES DOWAY FRENCH YeahIGetIt doroPls Offline sheMightBeRight 89 dwerk wideGkeyDance3 76 xqcCheer omeCheer Dmile zoro LMAO iguessbro doroScary haii SON omeBru wideSpeedCall plink laracroft ADHD yipe doroWaiting 67 FOWL doroLOL OfCourse tyler67 THYME peepoLost speed61 GOODMOOD Jercula ILOVECS CLOWN thatsCrazy xqcBleh omEING wideSpeedLaugh15 WHATTHEHELI RickyDicky jonkler wideSpeedPumpkin wideSpeedLaugh16 SPIDER chillCat LEEKED soblaugh BANANA wideSpeedLaugh21 Binoculars footstepmenace ome99 doroBanger GhankYou NO YES auntiePls OMEGADANCEBUTGHAST gkeyRide GENERATINGGODSEED perimeter sideeye omePfft MySunshine posture ??? twocatsfightingonacouch dSmile wideSpeedLaugh4 flirtt Suspicion zigzag YeatCat nom omeSad shomonting thinking agafat FirstTimeClanka DORVIS gasp RISING dd uncPLS domgBruh Deafge OMEGADANCEBUTFASTER kim3 Buggin speed8 .... d32 ome54 ohok minionBike Clown Explosion hackingCD JermaSoy MathTime MoneyRain PokiShare TakingNotes :0 :3 :33 :tf: !boost +1 0pixel 1DLove 3Head 3Heading 4House 4Shrug 4Weird 5Head AAAA Acknowledged ACTINUP ADHD agahi AIM AIRBALL AIWITHTHEBRAIDS Alarm ALE Alfred AlienDance AlienPls AlienPls2 AlienPls3 Aloo Alright amongE ANGRE ANOTHERONE Ant AREYOUAGIRL AREYOUAGIRLFtxQcYellingAtYou areyoufr AreYouSeriousRightNeow arnoldHalt arthur Assept AURA AwHellNah Aware AWOO AWOOGA axelF ayo bah BAND Banger BANGER banties Barack barryArrive Barry63 BantiesPaulBeef Based BASED BatChestAbove batman Batman batJAM batPls Beatles Bedge BEG BEGGING Bello BigD bieberDougie BELIEVERS BibleThump BINGO Bleh Bloons BOOBA bog BOOM BOOMIES BOINK BORGIR Borfday brbToilet Broadcaster brb Bruh BRUHMM bruv buh buhbye buhFlipExplode BUSSIN BUSSERS bye CanIHaveADollar cannySilly catAsk catBusiness CatCozy catDespair catEat catJAM catKiss catPls catSigh catSmash CatTime catTwerk CAUGHT Caught CaughtIn4K Celebrating CHADDING characterSelected CHATTERS chatting cheerleaders ChillGuy Chillin Cinema chilling clappi Clap classic CLEAN Clueless CLIPPERS CLOWNDETECTED COCKA cokeBreak COMEHERE Concerned Considering Cooked COPIUM crabPls Crunch CS2 Cuck Cuh D: damily Damn dansi dash Dave deadassFaint Delusional DemonTiming Dentge despair DespairRyan Devious DIESOFCRINGE Dime DinkDonk Dinema doggoSlava dogJAM DogLookingWickedAndCool doid dojaPls dome44 dome32 donowall donoWall doroAunt doroBleh dorobubu doroCD DoroCheer doroFiddy doroFlex doroGHOST doroHEAD doroKick doroL doroMAD doroPray doroRip doroSoy DoroTalkingAgain Dorozea doster DOUBTERS DRAIN Drake DRAMA dreamwastaken drooling drukiDnace drukiDnace2 duaKiss dudWhat EDGE EDM EDITING emo erinNya essaying ewphop eww EZ EZdodge Exerpas Explosion eyeroll fadedthanaho FARMING FeelsBadMan FeelsDankMan FeelsBlackScreen FeelsGladMan FeelsLagMan FeelsLateMan FeelsOkayMan FeelsStrongMan FeelsTiredMan FeelsWeirdMan FeelsWowMan fein FEINFEINFEINFEINFEINFEINFEINFEI FellOff fembajJAM Fiddy FiddyWtf FINALLY firewriting FirstTime FirstTimeBackseating FirstTimeChadder FirstTimeChatter FirstTimeEmoteFail FirstTimeGooner FirstTimePepega FirstTimeTest firsttimebuh FLASHBANG flightnotL Flirt Flushed fnaf footstep forsenCD forsenLaughingAtYou ForsenSingingAtYou forsenPls fortnite fr freakbob freakyfredday freddy Freedom FUNNY g32 GAGAGA gachiGASM gachiHYPER gamily GAMBA GameplayTime GAMING GatieG Gaught GENIUS GetALoadOfThisGuy gg GIGACHAD GIGACHAIR GIGACLAUS GIGAMODS GIGAMOD gigl gkeyFlip gkeyPregnantBounce gkeySMP gkeyUwu gkeywide gkeyWiding gkitten GivenUp girlBoss gkitten glorpaga glorpdetective glorp GlorpMeeting glorprave gmoney goaler goat goblin44 GODDID Gogging GoodBye Gooner gooner GoodTake GOONING GotCaughtTrolling GotEEM gothKiss gPls greetingsladies GREEDY GROOTING GRRR GULP GuitarTime GYAT HABIBI hackingCD HACKERMANS hai HAH HaltEinfachDeineFresseDuHurensohn HandsUp happi HARAM HarryStylesKiss Headbang healed HECOOKING heh HEHE HEHEHEHA Heisenberj HELLO HELP helvete Herewego hesRight heyywithrizz HEYYY hi hiii hiiii Hmm HOBBY HOLY HolyFuck homelessPOV HowDoWeTellHer HowDoWeTellHim hue HUH HUHHHHHHHHHH iAsked ICANT idiot iDrive IFISPEAK IfYouCantSeeThisEmoteUseExclamationMark7tv Ignored IGON imback IMAGINENOTHAVING7TVGETFUCKEDNON7TVUSERSIMAGINENOTHAVING7TVGETFUCKEDNON7TVUSERSIMAGINENOTHAVING7TVGET ImNotOk ImtiredBoss INTENSEGAMING islandboy ISeeYou itsover itstime Jackass jacob1 jacob2 jacob3 jacob4 jah Jammies JARVIS Jay JermaSoy jiggy job JOB Joel joever john Johnporkiscalling JokerHAHA JokerLaugh juh JumpScared JUMPSCARE JustAChillGuy JustAnotherDay JustHowItIs justinbieber KaiCenatOhiogyatwithskibiditoiletwatchingtheWrizzhappeningrightinfrontofhimwithfanumtaxtaxingthegyat KanyeStare KEKW KENOUGH KeyShaker kim3 kittyBANGER kittyBop KKalinka KKonaW KKool kratos Lamonting LastTimeChatter lava lebronArrive lebronJAM lebronTROLL LEBRONNN lemon Lemon LetsBingo LETHERCOOK LETSFUCKINGJOE LETSGO LieMeter life Life Listening LiterallyMe Lithuanian LittleTrolling LiveReaction LL LMAOFREAKY lmao Loading LOCKIN lockedin LOL Looking LookUp lore luh lurkk luton LULE LULW MAJ Madge ManchesterUnited Massive? MarblesTime Martin matSad maxwin MeRN me: MeWhenIBuyEgyptianProperty MEGALUL mee Memories merch mhm MicTime mikuPls mindloud modCheck ModAbuse MODDING Modding mods MODS Mog monakS monday monkeyListening monkeySip MONKA monkaTOS monkaW MONKE MinionHoting MoneyRain muted mutted MUGA MVP MVPOfFarallah MYHEARTILOVEDHER myIQ MYLIFE NAILS NAILSING NAHH NAHHH NAHHHH nananAYAYA NAUR NAvsEU Nerd niceguy NOCHECKMARKS NODDERS NOIDONTTHINKSO NoMaidens NOOPERS NOOOOO NOHORNY noonecares NOSHOT NOTED notListening notxqcL NOW NOWAY NOWAYING np nt nuhuh nyehehehe nyanPls nya o7 Ogre ohhh ohhhhhhhhh OHMYGAWDD ohneFinger ohno ohSHIT oj OK Okei okak OLDWORK OM om omE ome10 ome101 ome104 ome105 ome14 ome15 ome18 ome21 ome29 ome32 ome4 ome41 ome44 ome44444444 ome47 ome5 ome51 ome52 ome55 ome57 ome67 ome69 ome79 ome808 ome83 ome9 ome90 ome96 ome99 OMEGADANCE OMEGALUL OMEGALULiguess omEE omeJAM omeJudging omeOhSHIT omeScrajj omeStare OMEYES omeWiggle OMFG omgBruh ongang OneGuy ONEMORE OnMyWayToDoroMomHouse OOOO oopsie otag OuttaPocket OVERWATCH OVERWORKING OverwhelminglyWholesome owoCheer PagBounce PagChomp PagMan Panam parasocial Parasocial PARASOCIAL paris paul Paul paulNya PauseMan PAUSENEMOGU Peace PEEPEES peepoAds peepoBox peepoBelievers peepoClap peepoComfy peepoDJ peepoDoubters peepoEvil peepoFarmer peepoFat peepoGiggles peepoHappy peepoHey peepoHug peepoKiss peepoLeave peepoLegs peepoLove peepoMarch peepoPls peepoPride peepoRiot peepoSad peepoShy peepoSmile peepoStop peepoTalk pepeAgony pepeGun PepeHands pepeJAM PepeLaugh pepePoint PepePls pepeW Pepega PepegaAim PepegaChat PepegaReading PepoG Petter Pffttt Pffttt2 phew phpk pickle PianoTime Pipege pKitten pL Please pleading plink-182 plinkVibe plonk pmo Plotge PogO PogU pointless pokiFlirt pol POLICE Pondering popipopipipopipo poroPls POVbornbefore2000 ppHop ppL ppOverheat Prayge prePffttt PRIMERS PTSD pulNya PuzzleTime qq ragebait RAGEY RAHH RainTime RAMBOLMG RareParrot ratomilton RaveDance RaveTime ratio Reacting RealForsen ReallyMad RebeccaBlack Reddit RememberTheDays RibertJam RiddleMeThis RIPBOZO RIRI Rizzler RobertJam ROFL RoxyPotato RUNNING rt ryanArrive Sadding Sadge SADge SAJ SAVEME SCATTER saythatagain scawy SCHEISSE SCHIZO SCRAPETHATSHITJOHNNY SCHTOP sdd SERIOUSLY SEXO shogaNya Shits shutup Shruge silliness sisyphus Sippin Sits skip SLAY Sleepo Smile smh Smoge SmurfHey Smurfing SNACKING SNEAK SNIFFA sob SOLARFLARE songbird sotruebestie SOYSCREAM Speechless speed1 speed2 speed21 speed25 speed32 speed4 speed44 speed8 speed88 speedVibe spfLEAN:()wiltee_()tonyhawkproskater4:-:-:_FREEWAVE3-encinoman--:enteringwalmart:-wheezethelean-123 SpeedLaugh SpeedLeft SpeedR spongePls squadHips Stare Staring steve Steve SteerR StreamEnding STREAMER STREAMERSGIVINGTHEWORSTFUCKINGTAKESINEXISTENCE StoryTime Surfing SurE sus susDog Susge SUSSY Swag swagJAM ta tak TakingNotes TeamEDWARD test THATHIT ThatsJustMe ThePaulers TheVoices TheWolfInMe Thinking Thinking2 ThisChat ThisIsMinecraft TIMEOUT Tomfoolery totallylistening TriJam TriKool TriSad TRUEING TRIVSsorry ts Tuckge tuff TWEAK typeshit typhu UGH um UltraMad unibrow unemployment unmod uwu uuh VALORANT veryDoro VeryKey VeryPog VeryPogftxQcInTheShower vibePls VibePls VIDEOGAME VIEWERS vips Voices wade Waddup waga wah waiting Waiting WAHHH WAJAJA WAIT WAITWAITWAIT WakeTheFuckUpSamuraiWeHaveACityToBurn wallE waltuh walterShocked WalterVibe War WasZumPenis WATAFUCKEDUPDAY WatchingStream WAYTOODANK wdym WeAreLive WeDoNotCare WEDIDIT WEEWOO WeGood WePaid WHATAFUCKEDUPDAY WHAT WHATTT wheresmyhug Whenyourinnerwolfreleases WideAlERT WideCatGroove wideDvaAss WideHardo WidelebronJAM widemonkaGIGAftRobertDowneyJr wideprespeedlaugh WideRaveTime wideReacting wideSpeedLaugh3 widetime WidezyzzPls wig WineTime winton Wisdom woah Wokege WOT wot wrapitup WW wowie Xd xar2EDM xdd XDoubt xJAM xqc32 xqcBOZO xqcDespair xqcFuel xqcGoofy xqcL xqcSCHIZO xqcSlam xqcTake xqcTwerk xQcVeryWide YAAAY YamesBond YANITED YAPPING YeahThatsWhatIWouldaDid YEAHHH YEP YESS YIPIEE yonose Yoink YOOLOOKATTHISCATDOINITSLILDANCYDANCEINTOABREAKDANCEMOVE Yooo YOUDIED YouGotMe YouWouldntGetIt ZAMN ZhongXina zyzzBass zyzzJAM\"\"\"\n",
    "\n",
    "# Convert to list and clean \n",
    "emote_list = [emote.strip() for emote in tv7_emotes.split() if emote.strip()]\n",
    "\n",
    "# Remove any remaining duplicates (if any)\n",
    "unique_emotes = sorted(list(set(emote_list)))\n",
    "\n",
    "print(f\"Total unique emotes: {len(unique_emotes)}\")\n",
    "\n",
    "# Create the final shortened list\n",
    "final_emote_list = unique_emotes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "665a213a",
   "metadata": {},
   "source": [
    "july_2025:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9bf1ce40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in July 2025: 4625\n",
      "Number of Streams in July 2025: 26\n",
      "Number of Messages in July 2025: 179825\n",
      "Number of Users in July 2025: 9840\n",
      "          user  message_count\n",
      "0     BenXBari           8624\n",
      "1     JBIN2036           7848\n",
      "2      trek44_           6030\n",
      "3  GEORGIE1471           5324\n",
      "4   cr7vaibhav           5013\n",
      "5   balintboss           4639\n",
      "6    W1r3lesss           4484\n",
      "7     rautsi__           3970\n",
      "8    SchiKen44           2976\n",
      "9      Typhu25           2513\n",
      "Top 5 emotes in July 2025:\n",
      "LOL: 4934 times\n",
      "hai: 2794 times\n",
      "OMEYES: 2746 times\n",
      "OOOO: 2502 times\n",
      "WW: 2063 times\n",
      "Top 3 words in July 2025:\n",
      "the: 12611 times\n",
      "you: 10652 times\n",
      "i: 8784 times\n",
      "Top 5 busiest 5-minute intervals in July 2025:\n",
      "                          5min  message_count\n",
      "44   2025-07-03 18:05:00+02:00            729\n",
      "45   2025-07-03 18:10:00+02:00            609\n",
      "38   2025-07-03 17:35:00+02:00            602\n",
      "1376 2025-07-31 15:30:00+02:00            567\n",
      "37   2025-07-03 17:30:00+02:00            551\n",
      "Stream with the highest messages per minute:\n",
      "    stream  message_count                start_time                  end_time  \\\n",
      "25     381          11122 2025-07-31 14:47:04+02:00 2025-07-31 18:18:35+02:00   \n",
      "\n",
      "    duration_min  messages_per_min  \n",
      "25    211.516667         52.582145  \n",
      "chatters who chatted in every stream in July 2025:\n",
      "['Aluminiumminimumimmunity', 'ConorNewe', 'DonMascarpon', 'Fossabot', 'GEORGIE1471', 'JBIN2036', 'PurpCodd', 'StreamElements', 'W1r3lesss', 'balintboss', 'cr7vaibhav', 'trek44_']\n"
     ]
    }
   ],
   "source": [
    "# Filter only July 2025\n",
    "july_2025 = data[(data[\"date\"].dt.year == 2025) & (data[\"date\"].dt.month == 7)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in July 2025\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2025) & (first_messages[\"date\"].dt.month == 7)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in July 2025: {num_new_chatters}\")\n",
    "stream_counts = july_2025['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in July 2025: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in July 2025: {july_2025.shape[0]}\")\n",
    "print(f\"Number of Users in July 2025: {july_2025['user'].nunique()}\")\n",
    "user_counts = july_2025['user'].value_counts().reset_index()\n",
    "user_counts.sort_values('count').tail(10)\n",
    "\n",
    "# Count number of messages per user in July 2025\n",
    "user_counts = july_2025['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 3 users\n",
    "top_10_users = user_counts.head(10)\n",
    "\n",
    "print(top_10_users)\n",
    "\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in july_2025[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 3 emotes\n",
    "top_5_emotes = emote_counter.most_common(5)\n",
    "\n",
    "print(\"Top 5 emotes in July 2025:\")\n",
    "for emote, count in top_5_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Count all words from July messages\n",
    "word_counter = Counter()\n",
    "\n",
    "for message in july_2025[\"message\"]:\n",
    "    words = message.lower().split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Get top 3 most common words\n",
    "top_3_words = word_counter.most_common(3)\n",
    "\n",
    "print(\"Top 3 words in July 2025:\")\n",
    "for emote, count in top_3_words:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "july_2025 = july_2025.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "july_2025[\"5min\"] = july_2025[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = july_2025.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"Top 5 busiest 5-minute intervals in July 2025:\")\n",
    "print(top_5_fastest)\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = july_2025.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"Stream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# Get all unique stream IDs in July\n",
    "all_streams = set(july_2025[\"stream\"].unique())\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = july_2025.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"chatters who chatted in every stream in July 2025:\")\n",
    "print(users_in_every_stream)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f831210",
   "metadata": {},
   "source": [
    "May 2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e88a537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in May 2024: 2266\n",
      "Number of Streams in May 2024: 29\n",
      "Number of Messages in May 2024: 83053\n",
      "Number of Users in May 2024: 2266\n",
      "             user  message_count\n",
      "0    Martin_Gales           7506\n",
      "1       banties_x           3670\n",
      "2            oJov           3302\n",
      "3       1206paul_           2506\n",
      "4  StreamElements           2403\n",
      "5           roxa0           2309\n",
      "6           LX212           2226\n",
      "7     IvanOnMyOwn           2089\n",
      "8         klimzaa           1990\n",
      "9         Risc__V           1527\n",
      "Top 5 emotes in May 2024:\n",
      "mhm: 1967 times\n",
      "omE: 1368 times\n",
      "o7: 625 times\n",
      "OMEGALUL: 502 times\n",
      "hi: 474 times\n",
      "Top 3 words in May 2024:\n",
      "the: 11231 times\n",
      "you: 7300 times\n",
      "i: 7155 times\n",
      "Top 5 busiest 5-minute intervals in May 2024:\n",
      "                          5min  message_count\n",
      "1494 2024-05-27 23:55:00+02:00            339\n",
      "1149 2024-05-22 15:45:00+02:00            292\n",
      "1495 2024-05-28 00:00:00+02:00            225\n",
      "1558 2024-05-28 21:55:00+02:00            186\n",
      "1643 2024-05-29 19:55:00+02:00            172\n",
      "Stream with the highest messages per minute:\n",
      "    stream  message_count                start_time                  end_time  \\\n",
      "19      19           2089 2024-05-22 14:59:18+02:00 2024-05-22 17:03:08+02:00   \n",
      "\n",
      "    duration_min  messages_per_min  \n",
      "19    123.833333         16.869448  \n",
      "Chatters who chatted in every stream in May 2024:\n",
      "['1206paul_', 'Martin_Gales', 'StreamElements', 'balintboss', 'banties_x', 'dorozea']\n"
     ]
    }
   ],
   "source": [
    "# Filter only May 2024\n",
    "may_2024 = data[(data[\"date\"].dt.year == 2024) & (data[\"date\"].dt.month == 5)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in May 2024\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2024) & (first_messages[\"date\"].dt.month == 5)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in May 2024: {num_new_chatters}\")\n",
    "stream_counts = may_2024['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in May 2024: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in May 2024: {may_2024.shape[0]}\")\n",
    "print(f\"Number of Users in May 2024: {may_2024['user'].nunique()}\")\n",
    "user_counts = may_2024['user'].value_counts().reset_index()\n",
    "user_counts.sort_values('count').tail(10)\n",
    "\n",
    "# Count number of messages per user in May 2024\n",
    "user_counts = may_2024['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 users\n",
    "top_10_users = user_counts.head(10)\n",
    "\n",
    "print(top_10_users)\n",
    "\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in may_2024[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 5 emotes\n",
    "top_5_emotes = emote_counter.most_common(5)\n",
    "\n",
    "print(\"Top 5 emotes in May 2024:\")\n",
    "for emote, count in top_5_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Count all words from May messages\n",
    "word_counter = Counter()\n",
    "\n",
    "for message in may_2024[\"message\"]:\n",
    "    words = message.lower().split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Get top 3 most common words\n",
    "top_3_words = word_counter.most_common(3)\n",
    "\n",
    "print(\"Top 3 words in May 2024:\")\n",
    "for emote, count in top_3_words:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "may_2024 = may_2024.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "may_2024[\"5min\"] = may_2024[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = may_2024.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"Top 5 busiest 5-minute intervals in May 2024:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = may_2024.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"Stream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# Get all unique stream IDs in May\n",
    "all_streams = set(may_2024[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = may_2024.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"Chatters who chatted in every stream in May 2024:\")\n",
    "print(users_in_every_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb03020",
   "metadata": {},
   "source": [
    "AUG 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "291d77f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in August 2025: 4210\n",
      "Number of Streams in August 2025: 25\n",
      "Number of Messages in August 2025: 151681\n",
      "Number of Users in August 2025: 9146\n",
      "              user  message_count\n",
      "0         JBIN2036           7068\n",
      "1       cr7vaibhav           4634\n",
      "2       balintboss           4306\n",
      "3         BenXBari           4237\n",
      "4      GEORGIE1471           4139\n",
      "5         rautsi__           3155\n",
      "6          Odah_02           3051\n",
      "7  InverseEntropy_           2718\n",
      "8         KRIESEAX           2684\n",
      "9    lajosbarnabas           2661\n",
      "Top 5 emotes in August 2025:\n",
      "LOL: 3754 times\n",
      "ome44: 2672 times\n",
      "OMEYES: 2367 times\n",
      "hi: 2216 times\n",
      "sob: 2098 times\n",
      "Top 3 words in August 2025:\n",
      "the: 10251 times\n",
      "you: 9201 times\n",
      "is: 7932 times\n",
      "Top 5 busiest 5-minute intervals in August 2025:\n",
      "                          5min  message_count\n",
      "463  2025-08-11 19:20:00+02:00           1360\n",
      "464  2025-08-11 19:25:00+02:00            965\n",
      "462  2025-08-11 19:15:00+02:00            961\n",
      "1285 2025-08-31 19:10:00+02:00            554\n",
      "465  2025-08-11 19:30:00+02:00            520\n",
      "Stream with the highest messages per minute:\n",
      "   stream  message_count                start_time                  end_time  \\\n",
      "1     383           7384 2025-08-04 15:03:28+02:00 2025-08-04 19:02:33+02:00   \n",
      "\n",
      "   duration_min  messages_per_min  \n",
      "1    239.083333         30.884629  \n",
      "Chatters who chatted in every stream in August 2025:\n",
      "['Aluminiumminimumimmunity', 'Fossabot', 'GEORGIE1471', 'InverseEntropy_', 'JBIN2036', 'KRIESEAX', 'StreamElements', 'balintboss', 'rafa30___']\n"
     ]
    }
   ],
   "source": [
    "# Filter only August 2025\n",
    "aug_2025 = data[(data[\"date\"].dt.year == 2025) & (data[\"date\"].dt.month == 8)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in August 2025\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2025) & (first_messages[\"date\"].dt.month == 8)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in August 2025: {num_new_chatters}\")\n",
    "stream_counts = aug_2025['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in August 2025: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in August 2025: {aug_2025.shape[0]}\")\n",
    "print(f\"Number of Users in August 2025: {aug_2025['user'].nunique()}\")\n",
    "user_counts = aug_2025['user'].value_counts().reset_index()\n",
    "user_counts.sort_values('count').tail(10)\n",
    "\n",
    "# Count number of messages per user in August 2025\n",
    "user_counts = aug_2025['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 users\n",
    "top_10_users = user_counts.head(10)\n",
    "\n",
    "print(top_10_users)\n",
    "\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in aug_2025[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 5 emotes\n",
    "top_5_emotes = emote_counter.most_common(5)\n",
    "\n",
    "print(\"Top 5 emotes in August 2025:\")\n",
    "for emote, count in top_5_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Count all words from August messages\n",
    "word_counter = Counter()\n",
    "\n",
    "for message in aug_2025[\"message\"]:\n",
    "    words = message.lower().split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Get top 3 most common words\n",
    "top_3_words = word_counter.most_common(3)\n",
    "\n",
    "print(\"Top 3 words in August 2025:\")\n",
    "for emote, count in top_3_words:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "aug_2025 = aug_2025.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "aug_2025[\"5min\"] = aug_2025[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = aug_2025.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"Top 5 busiest 5-minute intervals in August 2025:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = aug_2025.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"Stream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# Get all unique stream IDs in August\n",
    "all_streams = set(aug_2025[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = aug_2025.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"Chatters who chatted in every stream in August 2025:\")\n",
    "print(users_in_every_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "804e2000",
   "metadata": {},
   "source": [
    "Sep 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "92d910a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in Sep 2025: 3971\n",
      "Number of Streams in Sep 2025: 26\n",
      "Number of Messages in Sep 2025: 170299\n",
      "Number of Users in Sep 2025: 9395\n",
      "             user  message_count\n",
      "0        BenXBari          14081\n",
      "1        JBIN2036           7935\n",
      "2        HALP____           6030\n",
      "3      balintboss           4705\n",
      "4         Odah_02           4609\n",
      "5        nishad13           4425\n",
      "6      cr7vaibhav           3581\n",
      "7   lajosbarnabas           3460\n",
      "8        KRIESEAX           3393\n",
      "9  StreamElements           3131\n",
      "Top 10 emotes in Sep 2025:\n",
      "WW: 3481 times\n",
      "LOL: 3422 times\n",
      "sob: 3216 times\n",
      "hi: 2306 times\n",
      "mhm: 1956 times\n",
      "om: 1745 times\n",
      "OMEYES: 1702 times\n",
      "OOOO: 1651 times\n",
      "ome51: 1584 times\n",
      "bye: 1508 times\n",
      "Top 3 words in Sep 2025:\n",
      "the: 14390 times\n",
      "to: 13160 times\n",
      "you: 12413 times\n",
      "Top 5 busiest 5-minute intervals in Sep 2025:\n",
      "                         5min  message_count\n",
      "271 2025-09-07 15:30:00+02:00            457\n",
      "137 2025-09-03 17:15:00+02:00            403\n",
      "139 2025-09-03 17:25:00+02:00            388\n",
      "431 2025-09-10 21:00:00+02:00            361\n",
      "71  2025-09-02 15:45:00+02:00            353\n",
      "Stream with the highest messages per minute:\n",
      "    stream  message_count                start_time                  end_time  \\\n",
      "20     427           7781 2025-09-24 14:15:24+02:00 2025-09-24 17:49:24+02:00   \n",
      "\n",
      "    duration_min  messages_per_min  \n",
      "20         214.0         36.359813  \n",
      "Chatters who chatted in every stream in Sep 2025:\n",
      "['Aluminiumminimumimmunity', 'DonMascarpon', 'Fossabot', 'JBIN2036', 'KRIESEAX', 'PiGE0N98', 'StreamElements', 'balintboss', 'nishad13', 'rafa30___']\n"
     ]
    }
   ],
   "source": [
    "# Filter only September 2025 \n",
    "sep_2025 = data[(data[\"date\"].dt.year == 2025) & (data[\"date\"].dt.month == 9)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in September 2025\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2025) & (first_messages[\"date\"].dt.month == 9)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in Sep 2025: {num_new_chatters}\")\n",
    "stream_counts = sep_2025['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in Sep 2025: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in Sep 2025: {sep_2025.shape[0]}\")\n",
    "print(f\"Number of Users in Sep 2025: {sep_2025['user'].nunique()}\")\n",
    "user_counts = sep_2025['user'].value_counts().reset_index()\n",
    "user_counts.sort_values('count').tail(10)\n",
    "\n",
    "# Count number of messages per user in September 2025\n",
    "user_counts = sep_2025['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 users\n",
    "top_10_users = user_counts.head(10)\n",
    "\n",
    "print(top_10_users)\n",
    "\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in sep_2025[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 5 emotes\n",
    "top_5_emotes = emote_counter.most_common(10)\n",
    "\n",
    "print(\"Top 10 emotes in Sep 2025:\")\n",
    "for emote, count in top_5_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Count all words from May messages\n",
    "word_counter = Counter()\n",
    "\n",
    "for message in sep_2025[\"message\"]:\n",
    "    words = message.lower().split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Get top 3 most common words\n",
    "top_3_words = word_counter.most_common(3)\n",
    "\n",
    "print(\"Top 3 words in Sep 2025:\")\n",
    "for emote, count in top_3_words:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "sep_2025 = sep_2025.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "sep_2025[\"5min\"] = sep_2025[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = sep_2025.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"Top 5 busiest 5-minute intervals in Sep 2025:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = sep_2025.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"Stream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# Get all unique stream IDs in Sep\n",
    "all_streams = set(sep_2025[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = sep_2025.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"Chatters who chatted in every stream in Sep 2025:\")\n",
    "print(users_in_every_stream)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd2496f",
   "metadata": {},
   "source": [
    "Oct 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a0ba5be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in Oct 2025: 3458\n",
      "Number of Streams in Oct 2025: 27\n",
      "Number of Messages in Oct 2025: 174954\n",
      "Number of Users in Oct 2025: 8868\n",
      "            user  message_count\n",
      "0       JBIN2036           7907\n",
      "1      rafa30___           7265\n",
      "2  lajosbarnabas           6545\n",
      "3       HALP____           6245\n",
      "4    polimpompis           6164\n",
      "5       BenXBari           5855\n",
      "6       nishad13           5094\n",
      "7     balintboss           4979\n",
      "8        Odah_02           3519\n",
      "9       KRIESEAX           3109\n",
      "Top 10 emotes in Oct 2025:\n",
      "sob: 4146 times\n",
      "LOL: 3142 times\n",
      "OMEYES: 3106 times\n",
      "WW: 2605 times\n",
      "mhm: 2340 times\n",
      "hi: 2305 times\n",
      "ome44: 1989 times\n",
      "bye: 1902 times\n",
      "om: 1801 times\n",
      "qq: 1697 times\n",
      "Top 3 words in Oct 2025:\n",
      "the: 14651 times\n",
      "you: 11574 times\n",
      "to: 10568 times\n",
      "Top 5 busiest 5-minute intervals in Oct 2025:\n",
      "                          5min  message_count\n",
      "1313 2025-10-30 16:45:00+01:00            546\n",
      "769  2025-10-17 19:20:00+02:00            504\n",
      "662  2025-10-15 19:30:00+02:00            430\n",
      "46   2025-10-01 18:45:00+02:00            388\n",
      "1307 2025-10-29 17:30:00+01:00            387\n",
      "Stream with the highest messages per minute:\n",
      "    stream  message_count                start_time                  end_time  \\\n",
      "25     458          10376 2025-10-30 16:41:06+01:00 2025-10-30 20:43:47+01:00   \n",
      "\n",
      "    duration_min  messages_per_min  \n",
      "25    242.683333         42.755305  \n",
      "Chatters who chatted in every stream in Oct 2025:\n",
      "['Aluminiumminimumimmunity', 'CrystalMethod1000', 'Fossabot', 'JBIN2036', 'KRIESEAX', 'StreamElements', 'balintboss', 'lajosbarnabas', 'noJokeee1', 'prince_explorer', 'rafa30___']\n"
     ]
    }
   ],
   "source": [
    "# Filter only October 2025 \n",
    "oct_2025 = data[(data[\"date\"].dt.year == 2025) & (data[\"date\"].dt.month == 10)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in October 2025\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2025) & (first_messages[\"date\"].dt.month == 10)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in Oct 2025: {num_new_chatters}\")\n",
    "stream_counts = oct_2025['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in Oct 2025: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in Oct 2025: {oct_2025.shape[0]}\")\n",
    "print(f\"Number of Users in Oct 2025: {oct_2025['user'].nunique()}\")\n",
    "user_counts = oct_2025['user'].value_counts().reset_index()\n",
    "user_counts.sort_values('count').tail(10)\n",
    "\n",
    "# Count number of messages per user in October 2025\n",
    "user_counts = oct_2025['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 users\n",
    "top_10_users = user_counts.head(10)\n",
    "\n",
    "print(top_10_users)\n",
    "\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in oct_2025[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 5 emotes\n",
    "top_5_emotes = emote_counter.most_common(10)\n",
    "\n",
    "print(\"Top 10 emotes in Oct 2025:\")\n",
    "for emote, count in top_5_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Count all words from October messages\n",
    "word_counter = Counter()\n",
    "\n",
    "for message in oct_2025[\"message\"]:\n",
    "    words = message.lower().split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Get top 3 most common words\n",
    "top_3_words = word_counter.most_common(3)\n",
    "\n",
    "print(\"Top 3 words in Oct 2025:\")\n",
    "for emote, count in top_3_words:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "oct_2025 = oct_2025.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "oct_2025[\"5min\"] = oct_2025[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = oct_2025.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"Top 5 busiest 5-minute intervals in Oct 2025:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = oct_2025.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"Stream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# Get all unique stream IDs in Oct\n",
    "all_streams = set(oct_2025[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = oct_2025.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"Chatters who chatted in every stream in Oct 2025:\")\n",
    "print(users_in_every_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bf9450db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in Nov 2025: 3401\n",
      "Number of Streams in Nov 2025: 25\n",
      "Number of Messages in Nov 2025: 218383\n",
      "Number of Users in Nov 2025: 8926\n",
      "            user  message_count\n",
      "0    polimpompis          12967\n",
      "1      rafa30___           9850\n",
      "2       nishad13           8825\n",
      "3       JBIN2036           7948\n",
      "4        Muuskie           7757\n",
      "5       erdeedge           6412\n",
      "6  lajosbarnabas           6394\n",
      "7       HALP____           6333\n",
      "8     cr7vaibhav           4946\n",
      "9     balintboss           4785\n",
      "Top 10 emotes in Nov 2025:\n",
      "WW: 5333 times\n",
      "hi: 5320 times\n",
      "SON: 3646 times\n",
      "OMEYES: 3632 times\n",
      "LOL: 3619 times\n",
      "sob: 3425 times\n",
      "mhm: 2982 times\n",
      "bye: 2855 times\n",
      "67: 2483 times\n",
      "OOOO: 2442 times\n",
      "Top 3 words in Nov 2025:\n",
      "the: 15777 times\n",
      "you: 11441 times\n",
      "to: 11172 times\n",
      "Top 5 busiest 5-minute intervals in Nov 2025:\n",
      "                        5min  message_count\n",
      "42 2025-11-01 18:35:00+01:00           1597\n",
      "41 2025-11-01 18:30:00+01:00           1527\n",
      "43 2025-11-01 18:40:00+01:00           1338\n",
      "44 2025-11-01 18:45:00+01:00           1321\n",
      "48 2025-11-01 19:05:00+01:00           1258\n",
      "Stream with the highest messages per minute:\n",
      "   stream  message_count                start_time                  end_time  \\\n",
      "0     460          18010 2025-11-01 15:06:46+01:00 2025-11-01 19:14:43+01:00   \n",
      "\n",
      "   duration_min  messages_per_min  \n",
      "0        247.95         72.635612  \n",
      "Chatters who chatted in every stream in Nov 2025:\n",
      "['CrystalMethod1000', 'DonMascarpon', 'Fossabot', 'JBIN2036', 'Muuskie', 'MyLastTwitchAccount', 'PiGE0N98', 'StreamElements', 'Zeololz', 'balintboss', 'bonk67', 'cr7vaibhav', 'erdeedge', 'haHAA_12_btw', 'noJokeee1', 'polimpompis', 'rafa30___']\n"
     ]
    }
   ],
   "source": [
    "# Filter only November 2025 \n",
    "nov_2025 = data[(data[\"date\"].dt.year == 2025) & (data[\"date\"].dt.month == 11)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in November 2025\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2025) & (first_messages[\"date\"].dt.month == 11)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in Nov 2025: {num_new_chatters}\")\n",
    "\n",
    "stream_counts = nov_2025['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in Nov 2025: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in Nov 2025: {nov_2025.shape[0]}\")\n",
    "print(f\"Number of Users in Nov 2025: {nov_2025['user'].nunique()}\")\n",
    "\n",
    "user_counts = nov_2025['user'].value_counts().reset_index()\n",
    "user_counts.sort_values('count').tail(10)\n",
    "\n",
    "# Count number of messages per user in November 2025\n",
    "user_counts = nov_2025['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 users\n",
    "top_10_users = user_counts.head(10)\n",
    "\n",
    "print(top_10_users)\n",
    "\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in nov_2025[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 5 emotes\n",
    "top_5_emotes = emote_counter.most_common(10)\n",
    "\n",
    "print(\"Top 10 emotes in Nov 2025:\")\n",
    "for emote, count in top_5_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Count all words from November messages\n",
    "word_counter = Counter()\n",
    "\n",
    "for message in nov_2025[\"message\"]:\n",
    "    words = message.lower().split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Get top 3 most common words\n",
    "top_3_words = word_counter.most_common(3)\n",
    "\n",
    "print(\"Top 3 words in Nov 2025:\")\n",
    "for emote, count in top_3_words:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "nov_2025 = nov_2025.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "nov_2025[\"5min\"] = nov_2025[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = nov_2025.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"Top 5 busiest 5-minute intervals in Nov 2025:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = nov_2025.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"Stream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# Get all unique stream IDs in Nov\n",
    "all_streams = set(nov_2025[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = nov_2025.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"Chatters who chatted in every stream in Nov 2025:\")\n",
    "print(users_in_every_stream)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1e7bcdef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in Dec 2025: 4876\n",
      "Number of Streams in Dec 2025: 25\n",
      "Number of Messages in Dec 2025: 268661\n",
      "Number of Users in Dec 2025: 11036\n",
      "\n",
      "Top 10 users in Dec 2025:\n",
      "            user  message_count\n",
      "0    polimpompis          14355\n",
      "1       erdeedge          13043\n",
      "2       nishad13          12711\n",
      "3       JBIN2036          11398\n",
      "4        Muuskie           9368\n",
      "5  lajosbarnabas           9067\n",
      "6       HALP____           7495\n",
      "7      rafa30___           7430\n",
      "8        Odah_02           5658\n",
      "9     balintboss           5212\n",
      "\n",
      "Top 10 emotes in Dec 2025:\n",
      "hi: 10350 times\n",
      "dwerk: 8309 times\n",
      "WW: 7170 times\n",
      "mhm: 4469 times\n",
      "OMEYES: 4424 times\n",
      "LOL: 4410 times\n",
      "bye: 3874 times\n",
      "sob: 3681 times\n",
      "BOOM: 3470 times\n",
      "67: 3066 times\n",
      "\n",
      "Top 3 words in Dec 2025:\n",
      "the: 18621 times\n",
      "i: 13794 times\n",
      "a: 13164 times\n",
      "\n",
      "Top 5 busiest 5-minute intervals in Dec 2025:\n",
      "                          5min  message_count\n",
      "499  2025-12-06 08:00:00+01:00            589\n",
      "176  2025-12-04 15:55:00+01:00            511\n",
      "1537 2025-12-28 23:50:00+01:00            501\n",
      "227  2025-12-05 09:20:00+01:00            469\n",
      "336  2025-12-05 18:25:00+01:00            463\n",
      "\n",
      "Stream with the highest messages per minute:\n",
      "    stream  message_count                start_time                  end_time  \\\n",
      "17     502          11283 2025-12-22 17:00:51+01:00 2025-12-22 21:15:04+01:00   \n",
      "\n",
      "    duration_min  messages_per_min  \n",
      "17    254.216667           44.3834  \n",
      "\n",
      "Chatters who chatted in every stream in Dec 2025:\n",
      "['Aluminiumminimumimmunity', 'Fossabot', 'HALP____', 'KRIESEAX', 'MyLastTwitchAccount', 'Nightbot', 'Pajkatt___', 'PiGE0N98', 'StreamElements', 'balintboss', 'erdeedge', 'flexus1771_', 'nishad13', 'noJokeee1', 'rafa30___']\n"
     ]
    }
   ],
   "source": [
    "# Filter only December 2025 \n",
    "dec_2025 = data[(data[\"date\"].dt.year == 2025) & (data[\"date\"].dt.month == 12)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in December 2025\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2025) & (first_messages[\"date\"].dt.month == 12)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in Dec 2025: {num_new_chatters}\")\n",
    "\n",
    "stream_counts = dec_2025['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in Dec 2025: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in Dec 2025: {dec_2025.shape[0]}\")\n",
    "print(f\"Number of Users in Dec 2025: {dec_2025['user'].nunique()}\")\n",
    "\n",
    "# Count number of messages per user in December 2025\n",
    "user_counts = dec_2025['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 users\n",
    "top_10_users = user_counts.head(10)\n",
    "print(\"\\nTop 10 users in Dec 2025:\")\n",
    "print(top_10_users)\n",
    "\n",
    "# --- Emote Analysis ---\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in dec_2025[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 10 emotes\n",
    "top_10_emotes = emote_counter.most_common(10)\n",
    "\n",
    "print(\"\\nTop 10 emotes in Dec 2025:\")\n",
    "for emote, count in top_10_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# --- Word Analysis ---\n",
    "# Count all words from December messages\n",
    "word_counter = Counter()\n",
    "\n",
    "for message in dec_2025[\"message\"]:\n",
    "    words = message.lower().split()\n",
    "    word_counter.update(words)\n",
    "\n",
    "# Get top 3 most common words\n",
    "top_3_words = word_counter.most_common(3)\n",
    "\n",
    "print(\"\\nTop 3 words in Dec 2025:\")\n",
    "for word, count in top_3_words:\n",
    "    print(f\"{word}: {count} times\")\n",
    "\n",
    "# --- Activity Spikes ---\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "dec_2025 = dec_2025.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "dec_2025[\"5min\"] = dec_2025[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = dec_2025.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"\\nTop 5 busiest 5-minute intervals in Dec 2025:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# --- Stream Velocity ---\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = dec_2025.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"\\nStream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# --- Loyalty Check ---\n",
    "# Get all unique stream IDs in Dec\n",
    "all_streams = set(dec_2025[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = dec_2025.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"\\nChatters who chatted in every stream in Dec 2025:\")\n",
    "print(users_in_every_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0fe6a65c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 2025 Annual Summary ---\n",
      "Number of new chatters in 2025: 69240\n",
      "Number of Streams in 2025: 308\n",
      "Number of Messages in 2025: 2388045\n",
      "Number of Users in 2025: 76715\n",
      "\n",
      "Top 10 users in 2025:\n",
      "             user  message_count\n",
      "0        JBIN2036          93140\n",
      "1      balintboss          54100\n",
      "2        BenXBari          49702\n",
      "3       W1r3lesss          44530\n",
      "4         trek44_          43682\n",
      "5   lajosbarnabas          42136\n",
      "6       rafa30___          36184\n",
      "7     polimpompis          34755\n",
      "8  StreamElements          32723\n",
      "9        stan_iv4          31857\n",
      "\n",
      "Top 10 emotes in 2025:\n",
      "speed1: 145143 times\n",
      "ome44: 138181 times\n",
      "LOL: 48325 times\n",
      "hi: 41412 times\n",
      "WW: 38208 times\n",
      "Smurfing: 37341 times\n",
      "OMEYES: 34871 times\n",
      "OOOO: 32434 times\n",
      "mhm: 29180 times\n",
      "qq: 25607 times\n",
      "\n",
      "Top 5 busiest 5-minute intervals in 2025:\n",
      "                           5min  message_count\n",
      "2382  2025-02-17 20:25:00+01:00           1791\n",
      "4621  2025-03-25 18:10:00+01:00           1750\n",
      "4663  2025-03-26 15:50:00+01:00           1601\n",
      "14925 2025-11-01 18:35:00+01:00           1597\n",
      "4619  2025-03-25 18:00:00+01:00           1554\n",
      "\n",
      "Fastest stream of 2025 (Messages per Minute):\n",
      "    stream  message_count                start_time                  end_time  \\\n",
      "41     243          21031 2025-02-17 16:32:39+01:00 2025-02-17 21:22:06+01:00   \n",
      "\n",
      "    duration_min  messages_per_min  \n",
      "41        289.45          72.65849  \n",
      "\n",
      "Chatters who chatted in every stream in 2025 (Total: 3):\n",
      "['Fossabot', 'StreamElements', 'balintboss']\n"
     ]
    }
   ],
   "source": [
    "# Filter for the whole year 2025 \n",
    "year_2025 = data[data[\"date\"].dt.year == 2025]\n",
    "\n",
    "# Find the first message date for each user (using the full dataset 'data')\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message ever was in 2025\n",
    "new_chatters = first_messages[first_messages[\"date\"].dt.year == 2025]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"--- 2025 Annual Summary ---\")\n",
    "print(f\"Number of new chatters in 2025: {num_new_chatters}\")\n",
    "\n",
    "stream_counts = year_2025['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in 2025: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in 2025: {year_2025.shape[0]}\")\n",
    "print(f\"Number of Users in 2025: {year_2025['user'].nunique()}\")\n",
    "\n",
    "# Count number of messages per user in 2025\n",
    "user_counts = year_2025['user'].value_counts().reset_index()\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 most active users\n",
    "top_10_users = user_counts.head(10)\n",
    "print(\"\\nTop 10 users in 2025:\")\n",
    "print(top_10_users)\n",
    "\n",
    "# --- Emote Analysis ---\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes from final_emote_list\n",
    "for message in year_2025[\"message\"]:\n",
    "    words = str(message).split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 10 emotes\n",
    "top_10_emotes = emote_counter.most_common(10)\n",
    "\n",
    "print(\"\\nTop 10 emotes in 2025:\")\n",
    "for emote, count in top_10_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "\n",
    "# --- Activity Spikes ---\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "year_2025 = year_2025.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "year_2025[\"5min\"] = year_2025[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = year_2025.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals of the year\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"\\nTop 5 busiest 5-minute intervals in 2025:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# --- Stream Velocity ---\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = year_2025.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"\\nFastest stream of 2025 (Messages per Minute):\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# --- Loyalty Check ---\n",
    "# Get all unique stream IDs in 2025\n",
    "all_streams = set(year_2025[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = year_2025.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every single stream of the year\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(f\"\\nChatters who chatted in every stream in 2025 (Total: {len(users_in_every_stream)}):\")\n",
    "print(users_in_every_stream)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3c8392b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top users by number of streams in 2025 (Excluding bots, Count >= 254):\n",
      "                    user  stream_count\n",
      "              balintboss           308\n",
      "                JBIN2036           307\n",
      "Aluminiumminimumimmunity           305\n",
      "             Wanderer039           286\n",
      "                 trek44_           284\n",
      "                 Zeololz           282\n",
      "               1206paul_           260\n",
      "            haHAA_12_btw           258\n",
      "               W1r3lesss           258\n",
      "                PiGE0N98           254\n",
      "\n",
      "Total users in this list: 10\n"
     ]
    }
   ],
   "source": [
    "# 1. Define the bots to exclude\n",
    "bots_to_exclude = [\"Fossabot\", \"StreamElements\",\"Nightbot\",]\n",
    "\n",
    "# 2. Filter the 2025 data to remove bots\n",
    "filtered_2025 = year_2025[~year_2025[\"user\"].isin(bots_to_exclude)]\n",
    "\n",
    "# 3. Group by user and count unique streams\n",
    "user_stream_participation = (\n",
    "    filtered_2025.groupby(\"user\")[\"stream\"]\n",
    "    .nunique()\n",
    "    .sort_values(ascending=False)\n",
    "    .reset_index(name=\"stream_count\")\n",
    ")\n",
    "\n",
    "# 4. Determine the threshold for the 10th position (including ties)\n",
    "if len(user_stream_participation) >= 10:\n",
    "    # Get the stream count value of the person at the 10th spot\n",
    "    threshold = user_stream_participation.iloc[9][\"stream_count\"]\n",
    "else:\n",
    "    threshold = user_stream_participation[\"stream_count\"].min() if not user_stream_participation.empty else 0\n",
    "\n",
    "# 5. Filter the list to include everyone who meets or exceeds that threshold\n",
    "top_users_by_streams = user_stream_participation[user_stream_participation[\"stream_count\"] >= threshold]\n",
    "\n",
    "print(f\"Top users by number of streams in 2025 (Excluding bots, Count >= {threshold}):\")\n",
    "print(top_users_by_streams.to_string(index=False))\n",
    "\n",
    "print(f\"\\nTotal users in this list: {len(top_users_by_streams)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6ce549e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "devilbabymamadrama    24077\n",
      "W1r3lesss             17283\n",
      "SchiKen44             12398\n",
      "rodrigo_20771         10155\n",
      "banties_x              8811\n",
      "uwu_cougar             7013\n",
      "HoneyKick              6907\n",
      "ACEiCLE                6001\n",
      "Typhu25                5716\n",
      "klimzaa                5252\n",
      "Name: speed1_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['speed1_count'] = year_2025['message'].str.count(r'\\bspeed1\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_speed1_users = (\n",
    "    year_2025.groupby('user')['speed1_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_speed1_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6cf9354",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "Typhu25         29089\n",
      "trek44_         14884\n",
      "shogalul         7169\n",
      "elluiti          6442\n",
      "JBIN2036         6164\n",
      "banties_x        5876\n",
      "Martin_Gales     4813\n",
      "stan_iv4         3791\n",
      "W1r3lesss        3591\n",
      "CrazeE420xd      3262\n",
      "Name: ome44_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['ome44_count'] = year_2025['message'].str.count(r'\\bome44\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_ome44_users = (\n",
    "    year_2025.groupby('user')['ome44_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_ome44_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c553e5c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "balintboss         3177\n",
      "Ivana_10           1667\n",
      "JBIN2036           1425\n",
      "cr7vaibhav         1285\n",
      "softarballtt       1227\n",
      "amirmasoud_2018    1112\n",
      "BenXBari           1005\n",
      "tiberiu0s           932\n",
      "Typhu25             885\n",
      "StunnerGR           799\n",
      "Name: LOL_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['LOL_count'] = year_2025['message'].str.count(r'\\bLOL\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_LOL_users = (\n",
    "    year_2025.groupby('user')['LOL_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_LOL_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3e08e32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "Aluminiumminimumimmunity    1771\n",
      "Muuskie                     1633\n",
      "lajosbarnabas               1575\n",
      "HALP____                    1312\n",
      "nishad13                    1261\n",
      "polimpompis                 1190\n",
      "trek44_                     1133\n",
      "erdeedge                     985\n",
      "SchiKen44                    777\n",
      "rautsi__                     770\n",
      "Name: hi_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['hi_count'] = year_2025['message'].str.count(r'\\bhi\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_hi_users = (\n",
    "    year_2025.groupby('user')['hi_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_hi_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "43446a10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "JBIN2036         1884\n",
      "klimzaa          1520\n",
      "lajosbarnabas    1454\n",
      "BenXBari         1192\n",
      "Typhu25          1122\n",
      "HALP____         1102\n",
      "nishad13         1084\n",
      "stan_iv4         1074\n",
      "balintboss       1006\n",
      "rafa30___         960\n",
      "Name: WW_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['WW_count'] = year_2025['message'].str.count(r'\\bWW\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_WW_users = (\n",
    "    year_2025.groupby('user')['WW_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_WW_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a47b1a41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "W1r3lesss             8149\n",
      "SchiKen44             4435\n",
      "devilbabymamadrama    4159\n",
      "HoneyKick             4090\n",
      "sisq                  3943\n",
      "trek44_               3079\n",
      "softarballtt          1656\n",
      "S_Face                1072\n",
      "elluiti               1023\n",
      "Typhu25                827\n",
      "Name: Smurfing_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['Smurfing_count'] = year_2025['message'].str.count(r'\\bSmurfing\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_Smurfing_users = (\n",
    "    year_2025.groupby('user')['Smurfing_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_Smurfing_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be318e41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "lajosbarnabas    4000\n",
      "trek44_          2482\n",
      "W1r3lesss        2330\n",
      "SchiKen44        1484\n",
      "polimpompis      1438\n",
      "CrazeE420xd      1403\n",
      "HALP____         1365\n",
      "elluiti          1316\n",
      "shogalul         1293\n",
      "BenXBari         1263\n",
      "Name: OMEYES_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['OMEYES_count'] = year_2025['message'].str.count(r'\\bOMEYES\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_OMEYES_users = (\n",
    "    year_2025.groupby('user')['OMEYES_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_OMEYES_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9c651127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "JBIN2036       3249\n",
      "stan_iv4       1147\n",
      "balintboss     1138\n",
      "trek44_        1052\n",
      "CrazeE420xd     972\n",
      "klimzaa         939\n",
      "StunnerGR       858\n",
      "W1r3lesss       853\n",
      "SchiKen44       748\n",
      "elluiti         734\n",
      "Name: OOOO_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['OOOO_count'] = year_2025['message'].str.count(r'\\bOOOO\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_OOOO_users = (\n",
    "    year_2025.groupby('user')['OOOO_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_OOOO_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "862e25b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user\n",
      "JBIN2036       2978\n",
      "balintboss     1804\n",
      "nishad13       1173\n",
      "W1r3lesss       920\n",
      "CrazeE420xd     882\n",
      "BenXBari        822\n",
      "polimpompis     778\n",
      "KRIESEAX        670\n",
      "erdeedge        663\n",
      "elluiti         661\n",
      "Name: mhm_count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "year_2025['mhm_count'] = year_2025['message'].str.count(r'\\bmhm\\b')\n",
    "\n",
    "# 2. Group by user, sum the counts, and get the top 10\n",
    "top_10_mhm_users = (\n",
    "    year_2025.groupby('user')['mhm_count']\n",
    "    .sum()\n",
    "    .sort_values(ascending=False)\n",
    "    .head(10)\n",
    ")\n",
    "\n",
    "print(top_10_mhm_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4faabdcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             date                      user message  stream\n",
      "3060434 2025-12-16 15:59:44+01:00                  JBIN2036    !arc     496\n",
      "3060437 2025-12-16 15:59:45+01:00                   klimzaa    !arc     496\n",
      "3060439 2025-12-16 15:59:46+01:00              thebigdogjay    !arc     496\n",
      "3060441 2025-12-16 15:59:46+01:00                  KRIESEAX    !arc     496\n",
      "3060444 2025-12-16 15:59:48+01:00                TheMixtape    !arc     496\n",
      "3060445 2025-12-16 15:59:48+01:00                  nishad13    !arc     496\n",
      "3060447 2025-12-16 15:59:50+01:00               Der_Stoppi_    !arc     496\n",
      "3060448 2025-12-16 15:59:50+01:00  Aluminiumminimumimmunity    !arc     496\n",
      "3060450 2025-12-16 15:59:53+01:00            kindheadbanger    !arc     496\n",
      "3060452 2025-12-16 15:59:55+01:00             ayuzawatakumi    !arc     496\n",
      "3060455 2025-12-16 15:59:56+01:00                   Odah_02    !arc     496\n",
      "3060466 2025-12-16 16:00:00+01:00                  mikirii_    !arc     496\n",
      "3060468 2025-12-16 16:00:00+01:00                  nishad13    !arc     496\n",
      "3060479 2025-12-16 16:00:04+01:00  Aluminiumminimumimmunity    !arc     496\n",
      "3060480 2025-12-16 16:00:04+01:00                  JBIN2036    !arc     496\n"
     ]
    }
   ],
   "source": [
    "result = data[data['message'] == '!arc'].head(15)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ada0e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats for JBIN2036 in 2025 ---\n",
      "1. Participation: Chatted in 307 out of 308 total streams\n",
      "2. Longest Streak: 293 consecutive days\n",
      "3. Most Chatted Stream: 2025-12-05 (Stream ID: 489) with 2025 messages\n",
      "4. Total Messages Sent: 93140\n",
      "5. Mentions by Others: 6033 times\n",
      "6. Top Mentioner: BenXBari (378 times)\n",
      "7. Messages with '@': 3358\n",
      "8. Who He Mentioned Most: @1206paul_ (209 times)\n",
      "9. Top 5 Emotes: [('ome44', 6164), ('OOOO', 3249), ('mhm', 2978), ('doroL', 2410), ('WW', 1884)]\n",
      "10. Avg Words/Message: 2.55\n",
      "11. Most Common Time: 18:35 (5-min interval)\n"
     ]
    }
   ],
   "source": [
    "from datetime import timedelta\n",
    "\n",
    "# 2. Filter for Year 2025\n",
    "data_2025 = data[data['date'].dt.year == 2025].copy()\n",
    "\n",
    "# Filter for the specific user \"JBIN2036\"\n",
    "target_user = \"JBIN2036\"\n",
    "df_target = data_2025[data_2025['user'] == target_user].copy()\n",
    "\n",
    "# --- STATISTICS CALCULATION ---\n",
    "\n",
    "# 1. Stream Participation: How many streams he chatted in vs total streams\n",
    "total_streams = data_2025['stream'].nunique()\n",
    "user_streams = df_target['stream'].nunique()\n",
    "\n",
    "# 2. Longest Streak (Consecutive Streams)\n",
    "# Get all unique streams in 2025 sorted by date to establish the timeline\n",
    "all_streams_ordered = data_2025.sort_values('date')['stream'].unique()\n",
    "\n",
    "# Identify which of those streams the target user participated in\n",
    "user_streams_set = set(df_target['stream'].unique())\n",
    "\n",
    "# Calculate the streak\n",
    "current_streak = 0\n",
    "longest_streak = 0\n",
    "\n",
    "for stream in all_streams_ordered:\n",
    "    if stream in user_streams_set:\n",
    "        current_streak += 1\n",
    "        longest_streak = max(longest_streak, current_streak)\n",
    "    else:\n",
    "        current_streak = 0\n",
    "\n",
    "# 3. Most Chatted Stream (Date and Message Count)\n",
    "if not df_target.empty:\n",
    "    # Group by stream identifier to find the one with most messages\n",
    "    stream_counts = df_target.groupby('stream').size()\n",
    "    most_active_stream_id = stream_counts.idxmax()\n",
    "    most_active_stream_msgs = stream_counts.max()\n",
    "    \n",
    "    # Find the primary date for this stream (the most frequent date associated with this stream ID)\n",
    "    stream_date = df_target[df_target['stream'] == most_active_stream_id]['date'].dt.date.mode()[0]\n",
    "    most_chatted_stream_info = f\"{stream_date} (Stream ID: {most_active_stream_id})\"\n",
    "else:\n",
    "    most_chatted_stream_info = \"N/A\"\n",
    "    most_active_stream_msgs = 0\n",
    "\n",
    "# 4. Total Messages Sent\n",
    "total_messages = len(df_target)\n",
    "\n",
    "# 5. Mentions by Others (Count \"JBIN2036\" or \"jbin\" in messages from others)\n",
    "df_others = data_2025[data_2025['user'] != target_user]\n",
    "# Regex: (?i) for case-insensitive, \\b for word boundaries\n",
    "mention_pattern = r'(?i)\\bJBIN2036\\b|\\bjbin\\b|\\b@JBIN2036\\b|\\b@jbin2036\\b'\n",
    "mentions_mask = df_others['message'].str.contains(mention_pattern, regex=True, na=False)\n",
    "total_mentions_by_others = mentions_mask.sum()\n",
    "\n",
    "# 6. Who Mentioned Him the Most\n",
    "if total_mentions_by_others > 0:\n",
    "    top_mentioner = df_others[mentions_mask]['user'].value_counts().idxmax()\n",
    "    top_mentioner_count = df_others[mentions_mask]['user'].value_counts().max()\n",
    "else:\n",
    "    top_mentioner = \"None\"\n",
    "    top_mentioner_count = 0\n",
    "\n",
    "# 7. Messages Containing \"@\"\n",
    "msgs_with_at = df_target['message'].str.contains('@', na=False).sum()\n",
    "\n",
    "# 8. Who He Mentioned Most (with count)\n",
    "if not df_target.empty:\n",
    "    # Extract all words starting with @\n",
    "    mentions_extracted = df_target['message'].str.extractall(r'(@\\w+)')\n",
    "    if not mentions_extracted.empty:\n",
    "        counts = mentions_extracted[0].value_counts()\n",
    "        top_user = counts.idxmax()\n",
    "        top_count = counts.max()\n",
    "        most_mentioned_user = f\"{top_user} ({top_count} times)\"\n",
    "    else:\n",
    "        most_mentioned_user = \"None\"\n",
    "else:\n",
    "    most_mentioned_user = \"None\"\n",
    "\n",
    "# 9. Top 5 Emotes Used (from final_emote_list)\n",
    "# Assuming final_emote_list is defined in your environment\n",
    "emote_counts = {}\n",
    "if not df_target.empty and 'final_emote_list' in locals():\n",
    "    for emote in final_emote_list:\n",
    "        # Count exact word matches for the emote\n",
    "        # re.escape ensures special characters in emote names don't break regex\n",
    "        pattern = r'\\b' + re.escape(emote) + r'\\b'\n",
    "        count = df_target['message'].str.count(pattern).sum()\n",
    "        if count > 0:\n",
    "            emote_counts[emote] = count\n",
    "    \n",
    "    # Sort by count descending and take top 5\n",
    "    top_5_emotes = sorted(emote_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "else:\n",
    "    top_5_emotes = []\n",
    "\n",
    "# 10. Average Words Per Message\n",
    "if not df_target.empty:\n",
    "    avg_words = df_target['message'].str.split().apply(len).mean()\n",
    "else:\n",
    "    avg_words = 0\n",
    "\n",
    "# 11. Most Common 5-minute Interval\n",
    "if not df_target.empty:\n",
    "    # Calculate minutes from midnight\n",
    "    minutes_from_midnight = df_target['date'].dt.hour * 60 + df_target['date'].dt.minute\n",
    "    # Integer divide by 5 to get the \"bin\" index\n",
    "    bin_index = minutes_from_midnight // 5\n",
    "    most_common_bin = bin_index.value_counts().idxmax()\n",
    "    \n",
    "    # Convert back to time string HH:MM\n",
    "    start_hour = (most_common_bin * 5) // 60\n",
    "    start_min = (most_common_bin * 5) % 60\n",
    "    most_active_time = f\"{int(start_hour):02d}:{int(start_min):02d}\"\n",
    "else:\n",
    "    most_active_time = \"N/A\"\n",
    "\n",
    "# --- OUTPUT RESULTS ---\n",
    "print(f\"--- Stats for {target_user} in 2025 ---\")\n",
    "print(f\"1. Participation: Chatted in {user_streams} out of {total_streams} total streams\")\n",
    "print(f\"2. Longest Streak: {longest_streak} consecutive streams\")\n",
    "print(f\"3. Most Chatted Stream: {most_chatted_stream_info} with {most_active_stream_msgs} messages\")\n",
    "print(f\"4. Total Messages Sent: {total_messages}\")\n",
    "print(f\"5. Mentions by Others: {total_mentions_by_others} times\")\n",
    "print(f\"6. Top Mentioner: {top_mentioner} ({top_mentioner_count} times)\")\n",
    "print(f\"7. Messages with '@': {msgs_with_at}\")\n",
    "print(f\"8. Who He Mentioned Most: {most_mentioned_user}\")\n",
    "print(f\"9. Top 5 Emotes: {top_5_emotes}\")\n",
    "print(f\"10. Avg Words/Message: {avg_words:.2f}\")\n",
    "print(f\"11. Most Common Time: {most_active_time} (5-min interval)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9adfbe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats for balintboss in 2025 ---\n",
      "1. Participation: Chatted in 308 out of 308 total streams\n",
      "2. Longest Streak: 308 consecutive days\n",
      "3. Most Chatted Stream: 2025-12-05 (Stream ID: 489) with 615 messages\n",
      "4. Total Messages Sent: 54100\n",
      "5. Mentions by Others: 12883 times\n",
      "6. Top Mentioner: lajosbarnabas (731 times)\n",
      "7. Messages with '@': 12469\n",
      "8. Who He Mentioned Most: @Ivana_10 (672 times)\n",
      "9. Top 5 Emotes: [('LOL', 3177), ('doroL', 2025), ('mhm', 1804), ('OOOO', 1138), ('dome32', 1137)]\n",
      "10. Avg Words/Message: 3.91\n",
      "11. Most Common Time: 15:25 (5-min interval)\n"
     ]
    }
   ],
   "source": [
    "# 2. Filter for Year 2025\n",
    "data_2025 = data[data['date'].dt.year == 2025].copy()\n",
    "\n",
    "# Filter for the specific user \"JBIN2036\"\n",
    "target_user = \"balintboss\"\n",
    "df_target = data_2025[data_2025['user'] == target_user].copy()\n",
    "\n",
    "# --- STATISTICS CALCULATION ---\n",
    "\n",
    "# 1. Stream Participation: How many streams he chatted in vs total streams\n",
    "total_streams = data_2025['stream'].nunique()\n",
    "user_streams = df_target['stream'].nunique()\n",
    "\n",
    "# 2. Longest Streak (Consecutive Streams)\n",
    "# Get all unique streams in 2025 sorted by date to establish the timeline\n",
    "all_streams_ordered = data_2025.sort_values('date')['stream'].unique()\n",
    "\n",
    "# Identify which of those streams the target user participated in\n",
    "user_streams_set = set(df_target['stream'].unique())\n",
    "\n",
    "# Calculate the streak\n",
    "current_streak = 0\n",
    "longest_streak = 0\n",
    "\n",
    "for stream in all_streams_ordered:\n",
    "    if stream in user_streams_set:\n",
    "        current_streak += 1\n",
    "        longest_streak = max(longest_streak, current_streak)\n",
    "    else:\n",
    "        current_streak = 0\n",
    "\n",
    "# 3. Most Chatted Stream (Date and Message Count)\n",
    "if not df_target.empty:\n",
    "    # Group by stream identifier to find the one with most messages\n",
    "    stream_counts = df_target.groupby('stream').size()\n",
    "    most_active_stream_id = stream_counts.idxmax()\n",
    "    most_active_stream_msgs = stream_counts.max()\n",
    "    \n",
    "    # Find the primary date for this stream (the most frequent date associated with this stream ID)\n",
    "    stream_date = df_target[df_target['stream'] == most_active_stream_id]['date'].dt.date.mode()[0]\n",
    "    most_chatted_stream_info = f\"{stream_date} (Stream ID: {most_active_stream_id})\"\n",
    "else:\n",
    "    most_chatted_stream_info = \"N/A\"\n",
    "    most_active_stream_msgs = 0\n",
    "\n",
    "# 4. Total Messages Sent\n",
    "total_messages = len(df_target)\n",
    "\n",
    "# 5. Mentions by Others (Count \"JBIN2036\" or \"jbin\" in messages from others)\n",
    "df_others = data_2025[data_2025['user'] != target_user]\n",
    "# Regex: (?i) for case-insensitive, \\b for word boundaries\n",
    "mention_pattern = r'(?i)\\bbalintboss\\b|\\bbalin\\b|\\bbalint\\b|\\bboss\\b|\\b@balintboss\\b'\n",
    "mentions_mask = df_others['message'].str.contains(mention_pattern, regex=True, na=False)\n",
    "total_mentions_by_others = mentions_mask.sum()\n",
    "\n",
    "# 6. Who Mentioned Him the Most\n",
    "if total_mentions_by_others > 0:\n",
    "    top_mentioner = df_others[mentions_mask]['user'].value_counts().idxmax()\n",
    "    top_mentioner_count = df_others[mentions_mask]['user'].value_counts().max()\n",
    "else:\n",
    "    top_mentioner = \"None\"\n",
    "    top_mentioner_count = 0\n",
    "\n",
    "# 7. Messages Containing \"@\"\n",
    "msgs_with_at = df_target['message'].str.contains('@', na=False).sum()\n",
    "\n",
    "# 8. Who He Mentioned Most (with count)\n",
    "if not df_target.empty:\n",
    "    # Extract all words starting with @\n",
    "    mentions_extracted = df_target['message'].str.extractall(r'(@\\w+)')\n",
    "    if not mentions_extracted.empty:\n",
    "        counts = mentions_extracted[0].value_counts()\n",
    "        top_user = counts.idxmax()\n",
    "        top_count = counts.max()\n",
    "        most_mentioned_user = f\"{top_user} ({top_count} times)\"\n",
    "    else:\n",
    "        most_mentioned_user = \"None\"\n",
    "else:\n",
    "    most_mentioned_user = \"None\"\n",
    "\n",
    "# 9. Top 5 Emotes Used (from final_emote_list)\n",
    "# Assuming final_emote_list is defined in your environment\n",
    "emote_counts = {}\n",
    "if not df_target.empty and 'final_emote_list' in locals():\n",
    "    for emote in final_emote_list:\n",
    "        # Count exact word matches for the emote\n",
    "        # re.escape ensures special characters in emote names don't break regex\n",
    "        pattern = r'\\b' + re.escape(emote) + r'\\b'\n",
    "        count = df_target['message'].str.count(pattern).sum()\n",
    "        if count > 0:\n",
    "            emote_counts[emote] = count\n",
    "    \n",
    "    # Sort by count descending and take top 5\n",
    "    top_5_emotes = sorted(emote_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "else:\n",
    "    top_5_emotes = []\n",
    "\n",
    "# 10. Average Words Per Message\n",
    "if not df_target.empty:\n",
    "    avg_words = df_target['message'].str.split().apply(len).mean()\n",
    "else:\n",
    "    avg_words = 0\n",
    "\n",
    "# 11. Most Common 5-minute Interval\n",
    "if not df_target.empty:\n",
    "    # Calculate minutes from midnight\n",
    "    minutes_from_midnight = df_target['date'].dt.hour * 60 + df_target['date'].dt.minute\n",
    "    # Integer divide by 5 to get the \"bin\" index\n",
    "    bin_index = minutes_from_midnight // 5\n",
    "    most_common_bin = bin_index.value_counts().idxmax()\n",
    "    \n",
    "    # Convert back to time string HH:MM\n",
    "    start_hour = (most_common_bin * 5) // 60\n",
    "    start_min = (most_common_bin * 5) % 60\n",
    "    most_active_time = f\"{int(start_hour):02d}:{int(start_min):02d}\"\n",
    "else:\n",
    "    most_active_time = \"N/A\"\n",
    "\n",
    "# --- OUTPUT RESULTS ---\n",
    "print(f\"--- Stats for {target_user} in 2025 ---\")\n",
    "print(f\"1. Participation: Chatted in {user_streams} out of {total_streams} total streams\")\n",
    "print(f\"2. Longest Streak: {longest_streak} consecutive streams\")\n",
    "print(f\"3. Most Chatted Stream: {most_chatted_stream_info} with {most_active_stream_msgs} messages\")\n",
    "print(f\"4. Total Messages Sent: {total_messages}\")\n",
    "print(f\"5. Mentions by Others: {total_mentions_by_others} times\")\n",
    "print(f\"6. Top Mentioner: {top_mentioner} ({top_mentioner_count} times)\")\n",
    "print(f\"7. Messages with '@': {msgs_with_at}\")\n",
    "print(f\"8. Who He Mentioned Most: {most_mentioned_user}\")\n",
    "print(f\"9. Top 5 Emotes: {top_5_emotes}\")\n",
    "print(f\"10. Avg Words/Message: {avg_words:.2f}\")\n",
    "print(f\"11. Most Common Time: {most_active_time} (5-min interval)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13af20a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats for BenXBari in 2025 ---\n",
      "1. Participation: Chatted in 166 out of 308 total streams\n",
      "2. Longest Streak: 83 consecutive days\n",
      "3. Most Chatted Stream: 2025-12-05 (Stream ID: 489) with 3334 messages\n",
      "4. Total Messages Sent: 49702\n",
      "5. Mentions by Others: 7886 times\n",
      "6. Top Mentioner: lajosbarnabas (692 times)\n",
      "7. Messages with '@': 6343\n",
      "8. Who He Mentioned Most: @lajosbarnabas (478 times)\n",
      "9. Top 5 Emotes: [('sob', 2467), ('hai', 1696), ('OMEYES', 1263), ('WW', 1192), ('LOL', 1005)]\n",
      "10. Avg Words/Message: 3.34\n",
      "11. Most Common Time: 15:25 (5-min interval)\n"
     ]
    }
   ],
   "source": [
    "# 2. Filter for Year 2025\n",
    "data_2025 = data[data['date'].dt.year == 2025].copy()\n",
    "\n",
    "# Filter for the specific user \"JBIN2036\"\n",
    "target_user = \"BenXBari\"\n",
    "df_target = data_2025[data_2025['user'] == target_user].copy()\n",
    "\n",
    "# --- STATISTICS CALCULATION ---\n",
    "\n",
    "# 1. Stream Participation: How many streams he chatted in vs total streams\n",
    "total_streams = data_2025['stream'].nunique()\n",
    "user_streams = df_target['stream'].nunique()\n",
    "\n",
    "# 2. Longest Streak (Consecutive Streams)\n",
    "# Get all unique streams in 2025 sorted by date to establish the timeline\n",
    "all_streams_ordered = data_2025.sort_values('date')['stream'].unique()\n",
    "\n",
    "# Identify which of those streams the target user participated in\n",
    "user_streams_set = set(df_target['stream'].unique())\n",
    "\n",
    "# Calculate the streak\n",
    "current_streak = 0\n",
    "longest_streak = 0\n",
    "\n",
    "for stream in all_streams_ordered:\n",
    "    if stream in user_streams_set:\n",
    "        current_streak += 1\n",
    "        longest_streak = max(longest_streak, current_streak)\n",
    "    else:\n",
    "        current_streak = 0\n",
    "\n",
    "# 3. Most Chatted Stream (Date and Message Count)\n",
    "if not df_target.empty:\n",
    "    # Group by stream identifier to find the one with most messages\n",
    "    stream_counts = df_target.groupby('stream').size()\n",
    "    most_active_stream_id = stream_counts.idxmax()\n",
    "    most_active_stream_msgs = stream_counts.max()\n",
    "    \n",
    "    # Find the primary date for this stream (the most frequent date associated with this stream ID)\n",
    "    stream_date = df_target[df_target['stream'] == most_active_stream_id]['date'].dt.date.mode()[0]\n",
    "    most_chatted_stream_info = f\"{stream_date} (Stream ID: {most_active_stream_id})\"\n",
    "else:\n",
    "    most_chatted_stream_info = \"N/A\"\n",
    "    most_active_stream_msgs = 0\n",
    "\n",
    "# 4. Total Messages Sent\n",
    "total_messages = len(df_target)\n",
    "\n",
    "# 5. Mentions by Others (Count \"JBIN2036\" or \"jbin\" in messages from others)\n",
    "df_others = data_2025[data_2025['user'] != target_user]\n",
    "# Regex: (?i) for case-insensitive, \\b for word boundaries\n",
    "mention_pattern = r'(?i)\\bBenXBari\\b|\\b@BenXBari\\b|\\b@benxbari\\b|\\bbenxbari\\b|\\bben\\b'\n",
    "mentions_mask = df_others['message'].str.contains(mention_pattern, regex=True, na=False)\n",
    "total_mentions_by_others = mentions_mask.sum()\n",
    "\n",
    "# 6. Who Mentioned Him the Most\n",
    "if total_mentions_by_others > 0:\n",
    "    top_mentioner = df_others[mentions_mask]['user'].value_counts().idxmax()\n",
    "    top_mentioner_count = df_others[mentions_mask]['user'].value_counts().max()\n",
    "else:\n",
    "    top_mentioner = \"None\"\n",
    "    top_mentioner_count = 0\n",
    "\n",
    "# 7. Messages Containing \"@\"\n",
    "msgs_with_at = df_target['message'].str.contains('@', na=False).sum()\n",
    "\n",
    "# 8. Who He Mentioned Most (with count)\n",
    "if not df_target.empty:\n",
    "    # Extract all words starting with @\n",
    "    mentions_extracted = df_target['message'].str.extractall(r'(@\\w+)')\n",
    "    if not mentions_extracted.empty:\n",
    "        counts = mentions_extracted[0].value_counts()\n",
    "        top_user = counts.idxmax()\n",
    "        top_count = counts.max()\n",
    "        most_mentioned_user = f\"{top_user} ({top_count} times)\"\n",
    "    else:\n",
    "        most_mentioned_user = \"None\"\n",
    "else:\n",
    "    most_mentioned_user = \"None\"\n",
    "\n",
    "# 9. Top 5 Emotes Used (from final_emote_list)\n",
    "# Assuming final_emote_list is defined in your environment\n",
    "emote_counts = {}\n",
    "if not df_target.empty and 'final_emote_list' in locals():\n",
    "    for emote in final_emote_list:\n",
    "        # Count exact word matches for the emote\n",
    "        # re.escape ensures special characters in emote names don't break regex\n",
    "        pattern = r'\\b' + re.escape(emote) + r'\\b'\n",
    "        count = df_target['message'].str.count(pattern).sum()\n",
    "        if count > 0:\n",
    "            emote_counts[emote] = count\n",
    "    \n",
    "    # Sort by count descending and take top 5\n",
    "    top_5_emotes = sorted(emote_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "else:\n",
    "    top_5_emotes = []\n",
    "\n",
    "# 10. Average Words Per Message\n",
    "if not df_target.empty:\n",
    "    avg_words = df_target['message'].str.split().apply(len).mean()\n",
    "else:\n",
    "    avg_words = 0\n",
    "\n",
    "# 11. Most Common 5-minute Interval\n",
    "if not df_target.empty:\n",
    "    # Calculate minutes from midnight\n",
    "    minutes_from_midnight = df_target['date'].dt.hour * 60 + df_target['date'].dt.minute\n",
    "    # Integer divide by 5 to get the \"bin\" index\n",
    "    bin_index = minutes_from_midnight // 5\n",
    "    most_common_bin = bin_index.value_counts().idxmax()\n",
    "    \n",
    "    # Convert back to time string HH:MM\n",
    "    start_hour = (most_common_bin * 5) // 60\n",
    "    start_min = (most_common_bin * 5) % 60\n",
    "    most_active_time = f\"{int(start_hour):02d}:{int(start_min):02d}\"\n",
    "else:\n",
    "    most_active_time = \"N/A\"\n",
    "\n",
    "# --- OUTPUT RESULTS ---\n",
    "print(f\"--- Stats for {target_user} in 2025 ---\")\n",
    "print(f\"1. Participation: Chatted in {user_streams} out of {total_streams} total streams\")\n",
    "print(f\"2. Longest Streak: {longest_streak} consecutive streams\")\n",
    "print(f\"3. Most Chatted Stream: {most_chatted_stream_info} with {most_active_stream_msgs} messages\")\n",
    "print(f\"4. Total Messages Sent: {total_messages}\")\n",
    "print(f\"5. Mentions by Others: {total_mentions_by_others} times\")\n",
    "print(f\"6. Top Mentioner: {top_mentioner} ({top_mentioner_count} times)\")\n",
    "print(f\"7. Messages with '@': {msgs_with_at}\")\n",
    "print(f\"8. Who He Mentioned Most: {most_mentioned_user}\")\n",
    "print(f\"9. Top 5 Emotes: {top_5_emotes}\")\n",
    "print(f\"10. Avg Words/Message: {avg_words:.2f}\")\n",
    "print(f\"11. Most Common Time: {most_active_time} (5-min interval)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc159311",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats for W1r3lesss in 2025 ---\n",
      "1. Participation: Chatted in 258 out of 308 total streams\n",
      "2. Longest Streak: 138 consecutive days\n",
      "3. Most Chatted Stream: 2025-03-20 (Stream ID: 270) with 1005 messages\n",
      "4. Total Messages Sent: 44530\n",
      "5. Mentions by Others: 2525 times\n",
      "6. Top Mentioner: trek44_ (165 times)\n",
      "7. Messages with '@': 6440\n",
      "8. Who He Mentioned Most: @lajosbarnabas (329 times)\n",
      "9. Top 5 Emotes: [('speed1', 17283), ('Smurfing', 8149), ('ome44', 3591), ('ome32', 2916), ('OMEYES', 2330)]\n",
      "10. Avg Words/Message: 3.51\n",
      "11. Most Common Time: 17:30 (5-min interval)\n"
     ]
    }
   ],
   "source": [
    "# 2. Filter for Year 2025\n",
    "data_2025 = data[data['date'].dt.year == 2025].copy()\n",
    "\n",
    "# Filter for the specific user \"JBIN2036\"\n",
    "target_user = \"W1r3lesss\"\n",
    "df_target = data_2025[data_2025['user'] == target_user].copy()\n",
    "\n",
    "# --- STATISTICS CALCULATION ---\n",
    "\n",
    "# 1. Stream Participation: How many streams he chatted in vs total streams\n",
    "total_streams = data_2025['stream'].nunique()\n",
    "user_streams = df_target['stream'].nunique()\n",
    "\n",
    "# 2. Longest Streak (Consecutive Streams)\n",
    "# Get all unique streams in 2025 sorted by date to establish the timeline\n",
    "all_streams_ordered = data_2025.sort_values('date')['stream'].unique()\n",
    "\n",
    "# Identify which of those streams the target user participated in\n",
    "user_streams_set = set(df_target['stream'].unique())\n",
    "\n",
    "# Calculate the streak\n",
    "current_streak = 0\n",
    "longest_streak = 0\n",
    "\n",
    "for stream in all_streams_ordered:\n",
    "    if stream in user_streams_set:\n",
    "        current_streak += 1\n",
    "        longest_streak = max(longest_streak, current_streak)\n",
    "    else:\n",
    "        current_streak = 0\n",
    "\n",
    "# 3. Most Chatted Stream (Date and Message Count)\n",
    "if not df_target.empty:\n",
    "    # Group by stream identifier to find the one with most messages\n",
    "    stream_counts = df_target.groupby('stream').size()\n",
    "    most_active_stream_id = stream_counts.idxmax()\n",
    "    most_active_stream_msgs = stream_counts.max()\n",
    "    \n",
    "    # Find the primary date for this stream (the most frequent date associated with this stream ID)\n",
    "    stream_date = df_target[df_target['stream'] == most_active_stream_id]['date'].dt.date.mode()[0]\n",
    "    most_chatted_stream_info = f\"{stream_date} (Stream ID: {most_active_stream_id})\"\n",
    "else:\n",
    "    most_chatted_stream_info = \"N/A\"\n",
    "    most_active_stream_msgs = 0\n",
    "\n",
    "# 4. Total Messages Sent\n",
    "total_messages = len(df_target)\n",
    "\n",
    "# 5. Mentions by Others (Count \"JBIN2036\" or \"jbin\" in messages from others)\n",
    "df_others = data_2025[data_2025['user'] != target_user]\n",
    "# Regex: (?i) for case-insensitive, \\b for word boundaries\n",
    "mention_pattern = r'(?i)\\bW1r3lesss\\b|\\bw1r3less\\b|\\bwireless\\b|\\bwire\\b|\\b@W1r3lesss\\b|\\b@w1r3lesss\\b'\n",
    "mentions_mask = df_others['message'].str.contains(mention_pattern, regex=True, na=False)\n",
    "total_mentions_by_others = mentions_mask.sum()\n",
    "\n",
    "# 6. Who Mentioned Him the Most\n",
    "if total_mentions_by_others > 0:\n",
    "    top_mentioner = df_others[mentions_mask]['user'].value_counts().idxmax()\n",
    "    top_mentioner_count = df_others[mentions_mask]['user'].value_counts().max()\n",
    "else:\n",
    "    top_mentioner = \"None\"\n",
    "    top_mentioner_count = 0\n",
    "\n",
    "# 7. Messages Containing \"@\"\n",
    "msgs_with_at = df_target['message'].str.contains('@', na=False).sum()\n",
    "\n",
    "# 8. Who He Mentioned Most (with count)\n",
    "if not df_target.empty:\n",
    "    # Extract all words starting with @\n",
    "    mentions_extracted = df_target['message'].str.extractall(r'(@\\w+)')\n",
    "    if not mentions_extracted.empty:\n",
    "        counts = mentions_extracted[0].value_counts()\n",
    "        top_user = counts.idxmax()\n",
    "        top_count = counts.max()\n",
    "        most_mentioned_user = f\"{top_user} ({top_count} times)\"\n",
    "    else:\n",
    "        most_mentioned_user = \"None\"\n",
    "else:\n",
    "    most_mentioned_user = \"None\"\n",
    "\n",
    "# 9. Top 5 Emotes Used (from final_emote_list)\n",
    "# Assuming final_emote_list is defined in your environment\n",
    "emote_counts = {}\n",
    "if not df_target.empty and 'final_emote_list' in locals():\n",
    "    for emote in final_emote_list:\n",
    "        # Count exact word matches for the emote\n",
    "        # re.escape ensures special characters in emote names don't break regex\n",
    "        pattern = r'\\b' + re.escape(emote) + r'\\b'\n",
    "        count = df_target['message'].str.count(pattern).sum()\n",
    "        if count > 0:\n",
    "            emote_counts[emote] = count\n",
    "    \n",
    "    # Sort by count descending and take top 5\n",
    "    top_5_emotes = sorted(emote_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "else:\n",
    "    top_5_emotes = []\n",
    "\n",
    "# 10. Average Words Per Message\n",
    "if not df_target.empty:\n",
    "    avg_words = df_target['message'].str.split().apply(len).mean()\n",
    "else:\n",
    "    avg_words = 0\n",
    "\n",
    "# 11. Most Common 5-minute Interval\n",
    "if not df_target.empty:\n",
    "    # Calculate minutes from midnight\n",
    "    minutes_from_midnight = df_target['date'].dt.hour * 60 + df_target['date'].dt.minute\n",
    "    # Integer divide by 5 to get the \"bin\" index\n",
    "    bin_index = minutes_from_midnight // 5\n",
    "    most_common_bin = bin_index.value_counts().idxmax()\n",
    "    \n",
    "    # Convert back to time string HH:MM\n",
    "    start_hour = (most_common_bin * 5) // 60\n",
    "    start_min = (most_common_bin * 5) % 60\n",
    "    most_active_time = f\"{int(start_hour):02d}:{int(start_min):02d}\"\n",
    "else:\n",
    "    most_active_time = \"N/A\"\n",
    "\n",
    "# --- OUTPUT RESULTS ---\n",
    "print(f\"--- Stats for {target_user} in 2025 ---\")\n",
    "print(f\"1. Participation: Chatted in {user_streams} out of {total_streams} total streams\")\n",
    "print(f\"2. Longest Streak: {longest_streak} consecutive streams\")\n",
    "print(f\"3. Most Chatted Stream: {most_chatted_stream_info} with {most_active_stream_msgs} messages\")\n",
    "print(f\"4. Total Messages Sent: {total_messages}\")\n",
    "print(f\"5. Mentions by Others: {total_mentions_by_others} times\")\n",
    "print(f\"6. Top Mentioner: {top_mentioner} ({top_mentioner_count} times)\")\n",
    "print(f\"7. Messages with '@': {msgs_with_at}\")\n",
    "print(f\"8. Who He Mentioned Most: {most_mentioned_user}\")\n",
    "print(f\"9. Top 5 Emotes: {top_5_emotes}\")\n",
    "print(f\"10. Avg Words/Message: {avg_words:.2f}\")\n",
    "print(f\"11. Most Common Time: {most_active_time} (5-min interval)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c937a239",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Stats for trek44_ in 2025 ---\n",
      "1. Participation: Chatted in 284 out of 308 total streams\n",
      "2. Longest Streak: 121 consecutive days\n",
      "3. Most Chatted Stream: 2025-03-14 (Stream ID: 265) with 841 messages\n",
      "4. Total Messages Sent: 43682\n",
      "5. Mentions by Others: 4354 times\n",
      "6. Top Mentioner: W1r3lesss (330 times)\n",
      "7. Messages with '@': 3050\n",
      "8. Who He Mentioned Most: @banties_x (265 times)\n",
      "9. Top 5 Emotes: [('ome44', 14884), ('speed1', 4848), ('Banger', 4010), ('Smurfing', 3079), ('OMEYES', 2482)]\n",
      "10. Avg Words/Message: 3.89\n",
      "11. Most Common Time: 16:00 (5-min interval)\n"
     ]
    }
   ],
   "source": [
    "# 2. Filter for Year 2025\n",
    "data_2025 = data[data['date'].dt.year == 2025].copy()\n",
    "\n",
    "# Filter for the specific user \"JBIN2036\"\n",
    "target_user = \"trek44_\"\n",
    "df_target = data_2025[data_2025['user'] == target_user].copy()\n",
    "\n",
    "# --- STATISTICS CALCULATION ---\n",
    "\n",
    "# 1. Stream Participation: How many streams he chatted in vs total streams\n",
    "total_streams = data_2025['stream'].nunique()\n",
    "user_streams = df_target['stream'].nunique()\n",
    "\n",
    "# 2. Longest Streak (Consecutive Streams)\n",
    "# Get all unique streams in 2025 sorted by date to establish the timeline\n",
    "all_streams_ordered = data_2025.sort_values('date')['stream'].unique()\n",
    "\n",
    "# Identify which of those streams the target user participated in\n",
    "user_streams_set = set(df_target['stream'].unique())\n",
    "\n",
    "# Calculate the streak\n",
    "current_streak = 0\n",
    "longest_streak = 0\n",
    "\n",
    "for stream in all_streams_ordered:\n",
    "    if stream in user_streams_set:\n",
    "        current_streak += 1\n",
    "        longest_streak = max(longest_streak, current_streak)\n",
    "    else:\n",
    "        current_streak = 0\n",
    "\n",
    "# 3. Most Chatted Stream (Date and Message Count)\n",
    "if not df_target.empty:\n",
    "    # Group by stream identifier to find the one with most messages\n",
    "    stream_counts = df_target.groupby('stream').size()\n",
    "    most_active_stream_id = stream_counts.idxmax()\n",
    "    most_active_stream_msgs = stream_counts.max()\n",
    "    \n",
    "    # Find the primary date for this stream (the most frequent date associated with this stream ID)\n",
    "    stream_date = df_target[df_target['stream'] == most_active_stream_id]['date'].dt.date.mode()[0]\n",
    "    most_chatted_stream_info = f\"{stream_date} (Stream ID: {most_active_stream_id})\"\n",
    "else:\n",
    "    most_chatted_stream_info = \"N/A\"\n",
    "    most_active_stream_msgs = 0\n",
    "\n",
    "# 4. Total Messages Sent\n",
    "total_messages = len(df_target)\n",
    "\n",
    "# 5. Mentions by Others (Count \"JBIN2036\" or \"jbin\" in messages from others)\n",
    "df_others = data_2025[data_2025['user'] != target_user]\n",
    "# Regex: (?i) for case-insensitive, \\b for word boundaries\n",
    "mention_pattern = r'(?i)\\btreklul\\b|\\b@treklul\\b|\\b@trek44\\b|\\btrek44\\b|\\bttrek_\\b|\\b@ttrek_\\b|\\btrek_x\\b|\\b@trek_x\\b|\\btrek\\b'\n",
    "mentions_mask = df_others['message'].str.contains(mention_pattern, regex=True, na=False)\n",
    "total_mentions_by_others = mentions_mask.sum()\n",
    "\n",
    "# 6. Who Mentioned Him the Most\n",
    "if total_mentions_by_others > 0:\n",
    "    top_mentioner = df_others[mentions_mask]['user'].value_counts().idxmax()\n",
    "    top_mentioner_count = df_others[mentions_mask]['user'].value_counts().max()\n",
    "else:\n",
    "    top_mentioner = \"None\"\n",
    "    top_mentioner_count = 0\n",
    "\n",
    "# 7. Messages Containing \"@\"\n",
    "msgs_with_at = df_target['message'].str.contains('@', na=False).sum()\n",
    "\n",
    "# 8. Who He Mentioned Most (with count)\n",
    "if not df_target.empty:\n",
    "    # Extract all words starting with @\n",
    "    mentions_extracted = df_target['message'].str.extractall(r'(@\\w+)')\n",
    "    if not mentions_extracted.empty:\n",
    "        counts = mentions_extracted[0].value_counts()\n",
    "        top_user = counts.idxmax()\n",
    "        top_count = counts.max()\n",
    "        most_mentioned_user = f\"{top_user} ({top_count} times)\"\n",
    "    else:\n",
    "        most_mentioned_user = \"None\"\n",
    "else:\n",
    "    most_mentioned_user = \"None\"\n",
    "\n",
    "# 9. Top 5 Emotes Used (from final_emote_list)\n",
    "# Assuming final_emote_list is defined in your environment\n",
    "emote_counts = {}\n",
    "if not df_target.empty and 'final_emote_list' in locals():\n",
    "    for emote in final_emote_list:\n",
    "        # Count exact word matches for the emote\n",
    "        # re.escape ensures special characters in emote names don't break regex\n",
    "        pattern = r'\\b' + re.escape(emote) + r'\\b'\n",
    "        count = df_target['message'].str.count(pattern).sum()\n",
    "        if count > 0:\n",
    "            emote_counts[emote] = count\n",
    "    \n",
    "    # Sort by count descending and take top 5\n",
    "    top_5_emotes = sorted(emote_counts.items(), key=lambda x: x[1], reverse=True)[:5]\n",
    "else:\n",
    "    top_5_emotes = []\n",
    "\n",
    "# 10. Average Words Per Message\n",
    "if not df_target.empty:\n",
    "    avg_words = df_target['message'].str.split().apply(len).mean()\n",
    "else:\n",
    "    avg_words = 0\n",
    "\n",
    "# 11. Most Common 5-minute Interval\n",
    "if not df_target.empty:\n",
    "    # Calculate minutes from midnight\n",
    "    minutes_from_midnight = df_target['date'].dt.hour * 60 + df_target['date'].dt.minute\n",
    "    # Integer divide by 5 to get the \"bin\" index\n",
    "    bin_index = minutes_from_midnight // 5\n",
    "    most_common_bin = bin_index.value_counts().idxmax()\n",
    "    \n",
    "    # Convert back to time string HH:MM\n",
    "    start_hour = (most_common_bin * 5) // 60\n",
    "    start_min = (most_common_bin * 5) % 60\n",
    "    most_active_time = f\"{int(start_hour):02d}:{int(start_min):02d}\"\n",
    "else:\n",
    "    most_active_time = \"N/A\"\n",
    "\n",
    "# --- OUTPUT RESULTS ---\n",
    "print(f\"--- Stats for {target_user} in 2025 ---\")\n",
    "print(f\"1. Participation: Chatted in {user_streams} out of {total_streams} total streams\")\n",
    "print(f\"2. Longest Streak: {longest_streak} consecutive streams\")\n",
    "print(f\"3. Most Chatted Stream: {most_chatted_stream_info} with {most_active_stream_msgs} messages\")\n",
    "print(f\"4. Total Messages Sent: {total_messages}\")\n",
    "print(f\"5. Mentions by Others: {total_mentions_by_others} times\")\n",
    "print(f\"6. Top Mentioner: {top_mentioner} ({top_mentioner_count} times)\")\n",
    "print(f\"7. Messages with '@': {msgs_with_at}\")\n",
    "print(f\"8. Who He Mentioned Most: {most_mentioned_user}\")\n",
    "print(f\"9. Top 5 Emotes: {top_5_emotes}\")\n",
    "print(f\"10. Avg Words/Message: {avg_words:.2f}\")\n",
    "print(f\"11. Most Common Time: {most_active_time} (5-min interval)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beeecca7",
   "metadata": {},
   "source": [
    "2026 Starts here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fb57fd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_emotes = [\n",
    "    'ome62','Staredown','PentagramOfFarallah','Gloving','footgammaRadiation',\n",
    "    'RAAAAAAAAGH','praise','doroRage','AndreSmithing','omePIECE','Rime',\n",
    "    'doroPIECE','kaiReading','Deadge','furi','blub','duh','nuh','gopissgirl',\n",
    "    'plong','Awesome','o','feaky','DoroThinking','evol','doro18','staycalm',\n",
    "    'omeFOWL','s','fairs','deal','moshimoshi','gn'\n",
    "]\n",
    "\n",
    "final_emote_list = list(set(final_emote_list) | set(new_emotes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "739a2105",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of new chatters in Jan 2026: 5120\n",
      "Number of Streams in Jan 2026: 28\n",
      "Number of Messages in Jan 2026: 245324\n",
      "Number of Users in Jan 2026: 11642\n",
      "\n",
      "Top 10 users in Jan 2026:\n",
      "            user  message_count\n",
      "0       erdeedge          12388\n",
      "1      rafa30___          10540\n",
      "2    polimpompis          10465\n",
      "3       JBIN2036           9478\n",
      "4       nishad13           8168\n",
      "5       HALP____           7328\n",
      "6        Muuskie           7228\n",
      "7     balintboss           5970\n",
      "8        Odah_02           4885\n",
      "9  lajosbarnabas           4395\n",
      "\n",
      "Top 10 emotes in Jan 2026:\n",
      "hi: 9452 times\n",
      "WW: 6907 times\n",
      "LOL: 3798 times\n",
      "omeFaded: 3583 times\n",
      "ome44: 3560 times\n",
      "bye: 3328 times\n",
      "sob: 3252 times\n",
      "mhm: 3032 times\n",
      "OMEYES: 2680 times\n",
      "OOOO: 2627 times\n",
      "\n",
      "Top 5 busiest 5-minute intervals in Jan 2026:\n",
      "                          5min  message_count\n",
      "50   2026-01-03 15:35:00+01:00            618\n",
      "1409 2026-01-30 16:55:00+01:00            613\n",
      "1408 2026-01-30 16:50:00+01:00            568\n",
      "393  2026-01-10 18:30:00+01:00            530\n",
      "403  2026-01-10 19:20:00+01:00            511\n",
      "\n",
      "Stream with the highest messages per minute:\n",
      "    stream  message_count                start_time                  end_time  \\\n",
      "10     519          17635 2026-01-10 18:12:50+01:00 2026-01-10 22:47:10+01:00   \n",
      "\n",
      "    duration_min  messages_per_min  \n",
      "10    274.333333         64.283111  \n",
      "\n",
      "Chatters who chatted in every stream in Jan 2026:\n",
      "['Aluminiumminimumimmunity', 'CrystalMethod1000', 'Fossabot', 'JBIN2036', 'Nightbot', 'StreamElements', 'balintboss', 'erdeedge', 'husvetteir', 'noJokeee1', 'rafa30___']\n"
     ]
    }
   ],
   "source": [
    "# Filter only January 2026\n",
    "jan_2026 = data[(data[\"date\"].dt.year == 2026) & (data[\"date\"].dt.month == 1)]\n",
    "\n",
    "# Find the first message date for each user\n",
    "first_messages = data.groupby(\"user\")[\"date\"].min().reset_index()\n",
    "\n",
    "# Filter users whose first message was in January 2026\n",
    "new_chatters = first_messages[\n",
    "    (first_messages[\"date\"].dt.year == 2026) & (first_messages[\"date\"].dt.month == 1)\n",
    "]\n",
    "\n",
    "# Get the number of new chatters\n",
    "num_new_chatters = new_chatters[\"user\"].nunique()\n",
    "\n",
    "print(f\"Number of new chatters in Jan 2026: {num_new_chatters}\")\n",
    "\n",
    "stream_counts = jan_2026['stream'].value_counts().reset_index()\n",
    "print(f\"Number of Streams in Jan 2026: {len(stream_counts)}\")\n",
    "print(f\"Number of Messages in Jan 2026: {jan_2026.shape[0]}\")\n",
    "print(f\"Number of Users in Jan 2026: {jan_2026['user'].nunique()}\")\n",
    "\n",
    "# Count number of messages per user in January 2026\n",
    "user_counts = jan_2026['user'].value_counts().reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "user_counts.columns = ['user', 'message_count']\n",
    "\n",
    "# Get the top 10 users\n",
    "top_10_users = user_counts.head(10)\n",
    "print(\"\\nTop 10 users in Jan 2026:\")\n",
    "print(top_10_users)\n",
    "\n",
    "# --- Emote Analysis ---\n",
    "# Initialize a Counter to store emote frequencies\n",
    "emote_counter = Counter()\n",
    "\n",
    "# Go through each message and count emotes\n",
    "for message in jan_2026[\"message\"]:\n",
    "    words = message.split()\n",
    "    for word in words:\n",
    "        if word in final_emote_list:\n",
    "            emote_counter[word] += 1\n",
    "\n",
    "# Get top 10 emotes\n",
    "top_10_emotes = emote_counter.most_common(10)\n",
    "\n",
    "print(\"\\nTop 10 emotes in Jan 2026:\")\n",
    "for emote, count in top_10_emotes:\n",
    "    print(f\"{emote}: {count} times\")\n",
    "\n",
    "# --- Activity Spikes ---\n",
    "# Make a copy to avoid SettingWithCopyWarning\n",
    "jan_2026 = jan_2026.copy()\n",
    "\n",
    "# Round timestamps to nearest 5-minute interval\n",
    "jan_2026[\"5min\"] = jan_2026[\"date\"].dt.floor(\"5min\")\n",
    "\n",
    "# Count messages per 5-minute interval\n",
    "message_counts = jan_2026.groupby(\"5min\").size().reset_index(name=\"message_count\")\n",
    "\n",
    "# Get top 5 busiest 5-minute intervals\n",
    "top_5_fastest = message_counts.sort_values(\"message_count\", ascending=False).head(5)\n",
    "print(\"\\nTop 5 busiest 5-minute intervals in Jan 2026:\")\n",
    "print(top_5_fastest)\n",
    "\n",
    "# --- Stream Velocity ---\n",
    "# Group by stream and compute message counts and time range\n",
    "stream_stats = jan_2026.groupby(\"stream\").agg(\n",
    "    message_count=(\"message\", \"count\"),\n",
    "    start_time=(\"date\", \"min\"),\n",
    "    end_time=(\"date\", \"max\")\n",
    ").reset_index()\n",
    "\n",
    "# Compute duration in minutes\n",
    "stream_stats[\"duration_min\"] = (stream_stats[\"end_time\"] - stream_stats[\"start_time\"]).dt.total_seconds() / 60\n",
    "\n",
    "# Avoid division by zero\n",
    "stream_stats = stream_stats[stream_stats[\"duration_min\"] > 0]\n",
    "\n",
    "# Calculate messages per minute\n",
    "stream_stats[\"messages_per_min\"] = stream_stats[\"message_count\"] / stream_stats[\"duration_min\"]\n",
    "\n",
    "# Get the stream with the highest messages per minute\n",
    "fastest_stream = stream_stats.sort_values(\"messages_per_min\", ascending=False).head(1)\n",
    "print(\"\\nStream with the highest messages per minute:\")\n",
    "print(fastest_stream)\n",
    "\n",
    "# --- Loyalty Check ---\n",
    "# Get all unique stream IDs in Jan\n",
    "all_streams = set(jan_2026[\"stream\"].unique())\n",
    "\n",
    "# Group by user and get the set of streams each user chatted in\n",
    "user_streams = jan_2026.groupby(\"user\")[\"stream\"].apply(set)\n",
    "\n",
    "# Filter users who chatted in every stream\n",
    "active_every_stream = user_streams[user_streams == all_streams]\n",
    "\n",
    "# Get just the user names\n",
    "users_in_every_stream = active_every_stream.index.tolist()\n",
    "print(\"\\nChatters who chatted in every stream in Jan 2026:\")\n",
    "print(users_in_every_stream)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
