{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ffcfe1e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import Counter\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "import pytz\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06ba2241",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the list of filenames from the configuration file\n",
    "with open('../../file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "# Iterate over each specified file\n",
    "for file in file_names:\n",
    "    full_path = f\"../../data/{file}\"\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message,stream_count])\n",
    "    stream_count = stream_count + 1\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\",\"stream\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9438250d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['date'] = pd.to_datetime(data['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d8bd6c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_utc_to_cet(df, date_column='date'):\n",
    "    \"\"\"\n",
    "    Convert UTC timestamps to Central European Time (CET/CEST) with proper DST handling\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the date column\n",
    "    date_column (str): Name of the column containing UTC timestamps\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with converted timestamps\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure timestamps are UTC aware\n",
    "    if df[date_column].dt.tz is None:\n",
    "        df[date_column] = df[date_column].dt.tz_localize('UTC')\n",
    "    elif df[date_column].dt.tz != pytz.UTC:\n",
    "        df[date_column] = df[date_column].dt.tz_convert('UTC')\n",
    "    \n",
    "    # Convert to CET/CEST (Europe/Berlin includes proper DST handling)\n",
    "    df[date_column] = df[date_column].dt.tz_convert('Europe/Berlin')\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "154ca00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = convert_utc_to_cet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60d7f810",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"user\"] = data[\"user\"].replace(\"Banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"chili_poe\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"CHILI_POE\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"Chili_poe\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"chili_conbacon\", \"chili_con_bacon\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"Wirelesss_\", \"W1r3lesss\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"treklul\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"ttrek_\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"trek_x\", \"trek44_\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"TriplesingleJ\", \"TripleSingleJames\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"uwu_cougar\", \"uuccugr\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"uuccugr_\",\"uuccugr\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"StanIV4_\", \"stan_iv4\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"Muuskie2\", \"Muuskie\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"nishad_more1311\", \"nishad13\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"softarballt\", \"softarr\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"softarballtt23\", \"softarr\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"lajosbarnabas\", \"lajoss__\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0b62c9e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all unique usernames\n",
    "unique_users = data['user'].unique()\n",
    "\n",
    "# Create a mapping from lowercase username to all variants\n",
    "\n",
    "user_variants = defaultdict(set)\n",
    "for user in unique_users:\n",
    "    user_variants[user.lower()].add(user)\n",
    "\n",
    "# Find usernames with different capitalization\n",
    "duplicate_users = {k: v for k, v in user_variants.items() if len(v) > 1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "067a8332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a mapping from all variants to the canonical (sorted first) variant\n",
    "variant_map = {}\n",
    "for variants in duplicate_users.values():\n",
    "    sorted_variants = sorted(variants)\n",
    "    canonical = sorted_variants[0]\n",
    "    for v in variants:\n",
    "        variant_map[v] = canonical\n",
    "\n",
    "# Replace usernames in 'user' column\n",
    "data['user'] = data['user'].apply(lambda u: variant_map.get(u, u))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1fdc93d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Big Losses (1000+ msg users) by Month in 2025 ---\n",
      "\n",
      "Month: 2025-01\n",
      "Count: 3\n",
      "Users: ['Pyczeg', 'abeKrd', 'astrologer95']\n",
      "\n",
      "Month: 2025-02\n",
      "Count: 5\n",
      "Users: ['Flashet67', 'brainofjfk', 'cukuLuLu41', 'fyredoor4', 'sercanwinchester']\n",
      "\n",
      "Month: 2025-03\n",
      "Count: 5\n",
      "Users: ['adevogado0_0', 'bilaltothefuture', 'flyphoenix777', 'moondog357', 'theprimephilosophy']\n",
      "\n",
      "Month: 2025-04\n",
      "Count: 2\n",
      "Users: ['Abraxas47_', 'winterwolf_Audrey1234']\n",
      "\n",
      "Month: 2025-05\n",
      "Count: 3\n",
      "Users: ['catsspurr', 'rodrigo_20771', 'selcuk_007']\n",
      "\n",
      "Month: 2025-06\n",
      "Count: 4\n",
      "Users: ['KarasuSora7', 'fawzarn004', 'prttymafaka', 'shishoti']\n",
      "\n",
      "Month: 2025-07\n",
      "Count: 6\n",
      "Users: ['K_Noxxx', 'Roonss', 'TripleSingleJames', 'ilahfauzan', 'per8immon', 'shenxir']\n",
      "\n",
      "Month: 2025-08\n",
      "Count: 10\n",
      "Users: ['PurpCodd', 'allgudnamesused12345', 'ertagon_', 'exitsixnine', 'moarmar', 'oxotter', 'tiberiu0s', 'voltzz06', 'yaonbuci', 'ベータ']\n",
      "\n",
      "Month: 2025-09\n",
      "Count: 6\n",
      "Users: ['HansoloSupremo', 'choghatasheleesinxd', 'fcukboii', 'kane_ong', 'man1ac007', 'sisq']\n",
      "\n",
      "Month: 2025-10\n",
      "Count: 7\n",
      "Users: ['DOROZEA_LOVER', 'JustALowkeyChillGuy', 'banties_x', 'devilbabymamadrama', 'giorgoslep', 'mrsanjijr064', 'thiccolas1234']\n",
      "\n",
      "Month: 2025-11\n",
      "Count: 8\n",
      "Users: ['StunnerGR', 'deathstr0ke97', 'khaliloalgiers16', 'linviolet', 'plz_dont_fall', 'roxa0', 'zimonsps', 'zymosz']\n",
      "\n",
      "Month: 2025-12\n",
      "Count: 18\n",
      "Users: ['1SKELTON', '1o1m4n', 'Aten369', 'Curiosity011', 'DesktopSetup', 'Greksallad', 'IceHotelZer0', 'Randy2D', 'Zoriemi', 'blakbilt', 'bonk67', 'cringeuss', 'fkaGabe', 'jvparisotto', 'moza420', 'nzexy', 'sisiliann', 'stanny781']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kardo\\AppData\\Local\\Temp\\ipykernel_20916\\3351139070.py:19: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  lost_in_2025['lost_month'] = lost_in_2025['last_seen'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "# 2. aggregate data by user to find their 'stats'\n",
    "# We need: \n",
    "#   - Total message count (to check the 1000+ condition)\n",
    "#   - Last message date (to check when they left)\n",
    "user_stats = data.groupby('user').agg(\n",
    "    total_messages=('message', 'count'),\n",
    "    last_seen=('date', 'max')\n",
    ").reset_index()\n",
    "\n",
    "# 3. Filter for 'Big Users' (1000+ messages)\n",
    "big_users = user_stats[user_stats['total_messages'] >= 1000].copy()\n",
    "\n",
    "# 4. Filter for users who left in 2025\n",
    "# We define 'lost' as: Last seen date is within 2025 \n",
    "# (and implicitly, they haven't been seen since, as 'max' captures the absolute last date)\n",
    "lost_in_2025 = big_users[big_users['last_seen'].dt.year == 2025].copy()\n",
    "\n",
    "# 5. Extract the month they were lost\n",
    "lost_in_2025['lost_month'] = lost_in_2025['last_seen'].dt.to_period('M')\n",
    "\n",
    "# 6. Group by month to get the list of users lost per month\n",
    "monthly_losses = lost_in_2025.groupby('lost_month')['user'].apply(list)\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"--- Big Losses (1000+ msg users) by Month in 2025 ---\")\n",
    "for period in sorted(monthly_losses.index):\n",
    "    users = monthly_losses[period]\n",
    "    print(f\"\\nMonth: {period}\")\n",
    "    print(f\"Count: {len(users)}\")\n",
    "    print(f\"Users: {users}\")\n",
    "\n",
    "# Optional: If you want a dataframe output\n",
    "result_df = lost_in_2025.groupby('lost_month').agg(\n",
    "    lost_user_count=('user', 'count'),\n",
    "    lost_users_list=('user', list)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "9b8a8e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- New VIPs (Joined in 2025, now have 1000+ msgs) ---\n",
      "\n",
      "Month: 2025-01\n",
      "Count: 17\n",
      "Users: ['ACEiCLE', 'Aten369', 'HoneyKick', 'KarasuSora7', 'W1r3lesss', 'Zodiak_L9', 'adevogado0_0', 'cringeuss', 'damm1jp', 'devilbabymamadrama', 'fawzarn004', 'finskbamse', 'kindheadbanger', 'm4estr3', 'theprimephilosophy', 'winterwolf_Audrey1234', 'yeldon64']\n",
      "\n",
      "Month: 2025-02\n",
      "Count: 19\n",
      "Users: ['ASSpaperman', 'Abraxas47_', 'DOROZEA_LOVER', 'K_Noxxx', 'PepegaKun', 'RELlKT', 'S_Face', 'SchiKen44', 'emantheman', 'flyphoenix777', 'fpv_dron', 'fredmckwacz', 'jvparisotto', 'moarmar', 'nizmo_ttn', 'per8immon', 'softarballtt', 'the_great_lord_walden', 'vladislav1997vb']\n",
      "\n",
      "Month: 2025-03\n",
      "Count: 19\n",
      "Users: ['Adevogado__33', 'BLAS1905', 'Der_Stoppi_', 'Ehas__', 'Foolsworn', 'KRIESEAX', 'Randy2D', 'StunnerGR', 'TheOldSeer', 'crxxpxer_', 'hellrazor_0', 'noJokeee1', 'prttymafaka', 'rafa30___', 'rodrigo_20771', 'teavapiti', 'teneightyp1080p', 'tiberiu0s', 'wundo']\n",
      "\n",
      "Month: 2025-04\n",
      "Count: 5\n",
      "Users: ['609__', 'Fein_BV', 'audrey_w_wolf1150', 'deathstr0ke97', 'dima_wide']\n",
      "\n",
      "Month: 2025-05\n",
      "Count: 7\n",
      "Users: ['7ordJaraxxus', 'ConorNewe', 'DonMascarpon', 'TheMixtape', 'c0refreAk', 'man1ac007', 'moza420']\n",
      "\n",
      "Month: 2025-06\n",
      "Count: 10\n",
      "Users: ['HitMarkerino', 'Odah_02', 'PurpCodd', 'gabrielzzq', 'ilahfauzan', 'j1740bm', 'l_silva4', 'oxotter', 'shishoti', 'yaonbuci']\n",
      "\n",
      "Month: 2025-07\n",
      "Count: 9\n",
      "Users: ['HALP____', 'InverseEntropy_', 'NikkelzeN', 'PkyBlinderDrLenz', 'choghatasheleesinxd', 'chuck_nokkers', 'nishad13', 'polimpompis', 'swawyz']\n",
      "\n",
      "Month: 2025-08\n",
      "Count: 8\n",
      "Users: ['CheezyMaxx', 'Iiidxnm12iii', 'khaliloalgiers16', 'loganxdr', 'tiberoo', 'timoo02', 'zymosz', '알래스카해달']\n",
      "\n",
      "Month: 2025-09\n",
      "Count: 8\n",
      "Users: ['CrystalMethod1000', 'FBI_Brad_Bellick', 'Muuskie', 'Swimtowin1', 'abdullaho15', 'amellie3x', 'plz_dont_fall', 'prince_explorer']\n",
      "\n",
      "Month: 2025-10\n",
      "Count: 7\n",
      "Users: ['IOMWMOI', 'RhinoRinat', 'bonk67', 'cheltm', 'chromejeromee', 'erdeedge', 'theluvros']\n",
      "\n",
      "Month: 2025-11\n",
      "Count: 5\n",
      "Users: ['Lyvione', 'Pajkatt___', 'RollCoke', 'hugojacksonjones', 'i_unique_gamer']\n",
      "\n",
      "Month: 2025-12\n",
      "Count: 4\n",
      "Users: ['DesktopSetup', 'flexus1771_', 'supaiiii', 'yop2u']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kardo\\AppData\\Local\\Temp\\ipykernel_20916\\723766162.py:15: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  winners_2025['join_month'] = winners_2025['first_seen'].dt.to_period('M')\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# 2. Aggregate to find 'First Seen' and Total Messages\n",
    "user_stats = data.groupby('user').agg(\n",
    "    total_messages=('message', 'count'),\n",
    "    first_seen=('date', 'min')  # We look for the EARLIEST date this time\n",
    ").reset_index()\n",
    "\n",
    "# 3. Filter for 'Big Users' (1000+ messages total)\n",
    "big_users = user_stats[user_stats['total_messages'] >= 1000].copy()\n",
    "\n",
    "# 4. Filter for users who STARTED in 2025\n",
    "# We define 'winner' as: First seen date is within 2025\n",
    "winners_2025 = big_users[big_users['first_seen'].dt.year == 2025].copy()\n",
    "\n",
    "# 5. Extract the month they joined\n",
    "winners_2025['join_month'] = winners_2025['first_seen'].dt.to_period('M')\n",
    "\n",
    "# 6. Group by month to get the list of winners per month\n",
    "monthly_winners = winners_2025.groupby('join_month')['user'].apply(list)\n",
    "\n",
    "# --- Display Results ---\n",
    "print(\"--- New VIPs (Joined in 2025, now have 1000+ msgs) ---\")\n",
    "for period in sorted(monthly_winners.index):\n",
    "    users = monthly_winners[period]\n",
    "    print(f\"\\nMonth: {period}\")\n",
    "    print(f\"Count: {len(users)}\")\n",
    "    print(f\"Users: {users}\")\n",
    "\n",
    "# Optional: Dataframe view\n",
    "winners_df = winners_2025.groupby('join_month').agg(\n",
    "    new_vip_count=('user', 'count'),\n",
    "    new_vip_list=('user', list)\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
