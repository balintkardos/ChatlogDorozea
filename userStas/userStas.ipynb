{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import pytz\n",
    "\n",
    "# Read the list of filenames from the configuration file\n",
    "with open('../file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "# Iterate over each specified file\n",
    "for file in file_names:\n",
    "    full_path = f\"../data/{file}\"\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message,stream_count])\n",
    "    stream_count = stream_count + 1\n",
    "\n",
    "# Create a DataFrame from the parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\",\"stream\"])\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "\n",
    "def convert_utc_to_cet(df, date_column='date'):\n",
    "    \"\"\"\n",
    "    Convert UTC timestamps to Central European Time (CET/CEST) with proper DST handling\n",
    "    \n",
    "    Parameters:\n",
    "    df (pd.DataFrame): DataFrame containing the date column\n",
    "    date_column (str): Name of the column containing UTC timestamps\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: DataFrame with converted timestamps\n",
    "    \"\"\"\n",
    "    # Make a copy to avoid modifying the original\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Ensure timestamps are UTC aware\n",
    "    if df[date_column].dt.tz is None:\n",
    "        df[date_column] = df[date_column].dt.tz_localize('UTC')\n",
    "    elif df[date_column].dt.tz != pytz.UTC:\n",
    "        df[date_column] = df[date_column].dt.tz_convert('UTC')\n",
    "    \n",
    "    # Convert to CET/CEST (Europe/Berlin includes proper DST handling)\n",
    "    df[date_column] = df[date_column].dt.tz_convert('Europe/Berlin')\n",
    "    \n",
    "    return df\n",
    "\n",
    "data = convert_utc_to_cet(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"user\"] = data[\"user\"].replace(\"Banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"banties1g\", \"banties_x\")\n",
    "data[\"user\"] = data[\"user\"].replace(\"fyodor_m_d1821\", \"fyredoor4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "529\n"
     ]
    }
   ],
   "source": [
    "message_counts = data[\"user\"].value_counts()\n",
    "users_above_1k = (message_counts >= 250).sum()\n",
    "print(users_above_1k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    50483.000000\n",
       "mean        26.518610\n",
       "std        446.612109\n",
       "min          1.000000\n",
       "25%          1.000000\n",
       "50%          3.000000\n",
       "75%          7.000000\n",
       "max      41207.000000\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message_counts.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "userName='W1r3lesss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Users warned multiple times count: 498\n",
      "Users warned but never typed Count: 1130\n",
      "Total warned: 4074\n",
      "Users warned multiple times AND never typed Count: 75\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kardo\\AppData\\Local\\Temp\\ipykernel_21280\\3088077461.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  fossa_warnings[\"warned_user\"] = fossa_warnings[\"message\"].str.extract(r'@(\\w+)')\n"
     ]
    }
   ],
   "source": [
    "# Filter messages from Fossabot\n",
    "fossa_warnings = data[data[\"user\"] == \"Fossabot\"]\n",
    "\n",
    "# Extract warned usernames from the warning message\n",
    "fossa_warnings[\"warned_user\"] = fossa_warnings[\"message\"].str.extract(r'@(\\w+)')\n",
    "\n",
    "# 1. Find people who received multiple warnings\n",
    "warn_counts = fossa_warnings[\"warned_user\"].value_counts()\n",
    "multiple_warned_users = warn_counts[warn_counts > 1].index.tolist()\n",
    "\n",
    "# 2. Find users who were warned but never typed in chat\n",
    "all_warned_users = set(fossa_warnings[\"warned_user\"].dropna())\n",
    "active_users = set(data[\"user\"]) - {\"Fossabot\"}  # All users except Fossabot\n",
    "silent_warned_users = list(all_warned_users - active_users)\n",
    "\n",
    "# 3. List of all warned people and its length\n",
    "all_warned_list = list(all_warned_users)\n",
    "num_warned = len(all_warned_list)\n",
    "\n",
    "# Print results\n",
    "print(\"Users warned multiple times count:\", len(multiple_warned_users))\n",
    "print(\"Users warned but never typed Count:\", len(silent_warned_users))\n",
    "print(\"Total warned:\", num_warned)\n",
    "\n",
    "# Find users who were warned multiple times AND never typed\n",
    "silent_multiple_warned_users = list(set(multiple_warned_users) & set(silent_warned_users))\n",
    "silent_multiple_warned_count = len(silent_multiple_warned_users)\n",
    "print(\"Users warned multiple times AND never typed Count:\", silent_multiple_warned_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 most warned users:\n",
      " warned_user\n",
      "uuccugr           16\n",
      "barisbalsuzenn    15\n",
      "dodo456a          13\n",
      "ttrek_            13\n",
      "Leftybrasco        9\n",
      "maxxus0            7\n",
      "riesenklotz        7\n",
      "ertagon_           6\n",
      "tomasvercetti_     6\n",
      "regnaltbatu        6\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Get top 10 most warned users from multiple_warned_users\n",
    "top_10_warned_users = warn_counts.head(10)  # Select the first 10 from the sorted warning count\n",
    "\n",
    "# Print results\n",
    "print(\"Top 10 most warned users:\\n\", top_10_warned_users)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "def calculate_user_stats(df):\n",
    "    \"\"\"Calculates various statistics for each user.\"\"\"\n",
    "    user_stats = []\n",
    "    \n",
    "    for user, user_df in df.groupby(\"user\"):\n",
    "        messages = user_df[\"message\"].tolist()\n",
    "        total_messages = len(messages)\n",
    "        total_words = sum(len(msg.split()) for msg in messages)\n",
    "        most_common_word = Counter(\" \".join(messages).split()).most_common(1)\n",
    "        \n",
    "        user_stats.append({\n",
    "            \"user\": user,\n",
    "            \"total_messages\": total_messages,\n",
    "            \"total_words\": total_words,\n",
    "            \"most_common_word\": most_common_word[0][0] if most_common_word else None,\n",
    "            \"most_common_word_count\": most_common_word[0][1] if most_common_word else 0,\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(user_stats)\n",
    "\n",
    "# Sample DataFrame\n",
    "# data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\", \"stream\"])\n",
    "\n",
    "def filter_active_users(data):\n",
    "    \"\"\"Filters users with more than 999 messages.\"\"\"\n",
    "    user_counts = data[\"user\"].value_counts()\n",
    "    active_users = user_counts[user_counts > 499].index\n",
    "    return data[data[\"user\"].isin(active_users)]\n",
    "\n",
    "# Filtering data and calculating stats\n",
    "data_filtered = filter_active_users(data)\n",
    "user_stats_df = calculate_user_stats(data_filtered)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_messages</th>\n",
       "      <th>total_words</th>\n",
       "      <th>most_common_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "      <td>264.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2918.560606</td>\n",
       "      <td>13993.602273</td>\n",
       "      <td>1385.250000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5443.004793</td>\n",
       "      <td>35062.828607</td>\n",
       "      <td>8653.659274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>500.000000</td>\n",
       "      <td>784.000000</td>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>677.500000</td>\n",
       "      <td>2711.750000</td>\n",
       "      <td>93.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1053.000000</td>\n",
       "      <td>4217.000000</td>\n",
       "      <td>165.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2198.750000</td>\n",
       "      <td>9757.000000</td>\n",
       "      <td>462.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>41207.000000</td>\n",
       "      <td>340933.000000</td>\n",
       "      <td>136660.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       total_messages    total_words  most_common_word_count\n",
       "count      264.000000     264.000000              264.000000\n",
       "mean      2918.560606   13993.602273             1385.250000\n",
       "std       5443.004793   35062.828607             8653.659274\n",
       "min        500.000000     784.000000               25.000000\n",
       "25%        677.500000    2711.750000               93.000000\n",
       "50%       1053.000000    4217.000000              165.000000\n",
       "75%       2198.750000    9757.000000              462.000000\n",
       "max      41207.000000  340933.000000           136660.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example output\n",
    "user_stats_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xqc32' 'the' 'ome44' 'is' 'you' 'speed1' 'FEET' 'FEIN' '1' 'NOWAYING'\n",
      " 'ome99' 'omE' 'PepeLaugh' 'I' 'English' 'LUL' 'lul' 'druskiDance' 'a'\n",
      " 'LOL' 'i' 'loeyaKEKW' 'LULW' 'RaveTime' 'ReallyMad' 'Listening'\n",
      " '@dorozea' '?' 'mhm' 'u' 'bye' 'OMEGALUL' 'andrea540Joy' 'hi' 'lol'\n",
      " 'doro' 'ICANT' 'BangbooBounce' 'DORO' 'Yay' 'PewPewPew'\n",
      " 'dorozeaTouchingyou' 'forsenLaughingAtYou' 'YEP' 'Clap' 'ome808'\n",
      " 'STREAMER' 'DinoDance' 'xd' 'LETSGO' 'WW' 'forsenE' '!' 'dorozeaSlam'\n",
      " 'moustache' 'om' 'Joel' 'qq' 'RalpherZ']\n"
     ]
    }
   ],
   "source": [
    "# Assuming user_stats_df is your DataFrame\n",
    "unique_words = user_stats_df['most_common_word'].unique()\n",
    "\n",
    "# If you want to print them\n",
    "print(unique_words)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
