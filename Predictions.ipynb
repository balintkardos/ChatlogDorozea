{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected to reach 500 average viewers on: 2025-08-06\n",
      "Expected to reach 300 active tier 1 & prime subs on: 2025-03-22\n",
      "Expected to reach 5000000 watch hours on: 2029-08-30\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the list of filenames from the configuration file\n",
    "with open('file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "\n",
    "# Parse each file\n",
    "for file in file_names:\n",
    "    full_path = f\"data\\\\{file}\"\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message, stream_count])\n",
    "    stream_count += 1\n",
    "\n",
    "# Create a DataFrame from parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\", \"stream\"])\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['first_message'] = data.groupby('user').cumcount().apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "# Calculate stream-level statistics\n",
    "stream_stats = data.groupby('stream').agg(\n",
    "    first_messages=('first_message', 'sum'),\n",
    "    total_messages=('stream', 'size'),\n",
    "    unique_chatters=('user', 'nunique')\n",
    ")\n",
    "\n",
    "# Calculate stream duration in seconds\n",
    "stream_stats['stream_length'] = data.groupby('stream')['date'].agg(lambda x: (x.max() - x.min()).total_seconds())\n",
    "stream_stats['stream_length_hour'] = stream_stats['stream_length'] / 3600\n",
    "\n",
    "# Load additional statistics from Excel\n",
    "exelStats = pd.read_excel('DorozeaStreamStats.xlsx', sheet_name='Munkalap1', header=None, names=['stream', 'avg', 'max', 'follow', 'games'], skiprows=1)\n",
    "\n",
    "# Merge stream statistics with Excel data\n",
    "stream_stats = pd.merge(stream_stats, exelStats, on='stream', how='right')\n",
    "stream_stats['hours_watched'] = stream_stats['stream_length_hour'] * stream_stats['avg']\n",
    "\n",
    "# Sub and gift data extraction\n",
    "subData = data[data.apply(lambda row: row['user'].lower() in row['message'].lower(), axis=1)]\n",
    "giftedData = subData[subData['message'].str.contains(' sub ', case=False, na=False)]\n",
    "\n",
    "# Calculate gifted subs and unique gifters per stream\n",
    "unique_gifters = giftedData.groupby('stream')['user'].nunique()\n",
    "stream_stats = pd.merge(stream_stats, unique_gifters.rename('gifters'), on='stream', how='left').fillna(0)\n",
    "\n",
    "gift_per_stream = giftedData.groupby('stream')['user'].count()\n",
    "stream_stats = pd.merge(stream_stats, gift_per_stream.rename('gift'), on='stream', how='left').fillna(0)\n",
    "\n",
    "# Calculate prime subs, and tier subs\n",
    "\n",
    "primeData = subData[subData['message'].str.contains('Prime', case=False, na=False)]\n",
    "prime_per_stream = primeData.groupby('stream')['user'].count()\n",
    "stream_stats = pd.merge(stream_stats, prime_per_stream.rename('prime'), on='stream', how='left').fillna(0)\n",
    "\n",
    "# Extract tier subs and calculate per stream\n",
    "trueSub = subData[~subData['message'].str.contains('Prime|raiders|gifting|gifted', case=False)]\n",
    "trueSub = trueSub[trueSub['message'].str.contains(' subscribed at ', case=False)]\n",
    "\n",
    "for tier in [1, 2, 3]:\n",
    "    tier_data = trueSub[trueSub['message'].str.contains(f'Tier {tier}', case=False)]\n",
    "    tier_per_stream = tier_data.groupby('stream')['user'].count()\n",
    "    stream_stats = pd.merge(stream_stats, tier_per_stream.rename(f'tier{tier}'), on='stream', how='left').fillna(0)\n",
    "\n",
    "# Add stream date information\n",
    "data['date_only'] = data['date'].dt.date\n",
    "stream_date = data.groupby('stream')['date_only'].min().reset_index().rename(columns={'date_only': 'stream_date'})\n",
    "stream_stats = pd.merge(stream_stats, stream_date, on='stream', how='left')\n",
    "stream_stats['stream_date'] = pd.to_datetime(stream_stats['stream_date'])\n",
    "\n",
    "# Calculate active subs, prime, and tiers in the last 30 days\n",
    "for col in ['tier1', 'prime', 'tier2', 'tier3', 'gift']:\n",
    "    active_col = f'active_{col}'\n",
    "    active_subs = []\n",
    "    for i in range(len(stream_stats)):\n",
    "        current_date = stream_stats.iloc[i]['stream_date']\n",
    "        mask = (stream_stats['stream_date'] <= current_date) & (stream_stats['stream_date'] > current_date - pd.Timedelta(days=30))\n",
    "        active_count = stream_stats.loc[mask, col].sum()\n",
    "        active_subs.append(active_count)\n",
    "    stream_stats[active_col] = active_subs\n",
    "\n",
    "# Total active subs calculation\n",
    "stream_stats['all_sub'] = stream_stats[['tier1', 'tier2', 'tier3', 'prime', 'gift']].sum(axis=1)\n",
    "\n",
    "# Cumulative watch hours\n",
    "initial_watch_hours = 97068\n",
    "stream_stats['watch_hour'] = stream_stats['hours_watched'].cumsum() + initial_watch_hours\n",
    "\n",
    "\n",
    "# Time since first stream\n",
    "stream_stats['days_since_first_stream'] = (stream_stats['stream_date'] - stream_stats['stream_date'].min()).dt.days\n",
    "\n",
    "# Linear regression to predict average viewers reaching 500\n",
    "X = stream_stats[['days_since_first_stream']]\n",
    "y = stream_stats['avg']\n",
    "model = LinearRegression().fit(X, y)\n",
    "target_viewers = 500\n",
    "predicted_days = (target_viewers - model.intercept_) / model.coef_[0]\n",
    "predicted_date = stream_stats['stream_date'].min() + pd.to_timedelta(predicted_days, unit='d')\n",
    "print(f\"Expected to reach {target_viewers} average viewers on: {predicted_date.date()}\")\n",
    "\n",
    "# Linear regression to predict 300 active subs (tier1 + prime)\n",
    "stream_stats_no_may = stream_stats[stream_stats['stream_date'] > '2024-05-31'].copy()\n",
    "X = stream_stats_no_may[['days_since_first_stream']]\n",
    "y = stream_stats_no_may['active_tier1'] + stream_stats_no_may['active_prime']\n",
    "model = LinearRegression().fit(X, y)\n",
    "target_active_subs = 300\n",
    "predicted_days = (target_active_subs - model.intercept_) / model.coef_[0]\n",
    "predicted_date = stream_stats_no_may['stream_date'].min() + pd.to_timedelta(predicted_days, unit='d')\n",
    "print(f\"Expected to reach {target_active_subs} active tier 1 & prime subs on: {predicted_date.date()}\")\n",
    "\n",
    "# Polynomial regression to predict 5M watch hours\n",
    "X = stream_stats[['days_since_first_stream']]\n",
    "y = stream_stats['watch_hour']\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "model_poly = LinearRegression().fit(X_poly, y)\n",
    "\n",
    "# Solve quadratic equation for 5M watch hours\n",
    "target_hours = 5000000\n",
    "beta_0, beta_1, beta_2 = model_poly.intercept_, model_poly.coef_[1], model_poly.coef_[2]\n",
    "discriminant = beta_1**2 - 4*beta_2*(beta_0 - target_hours)\n",
    "\n",
    "if discriminant >= 0:\n",
    "    predicted_days_1 = (-beta_1 + np.sqrt(discriminant)) / (2 * beta_2)\n",
    "    predicted_days_2 = (-beta_1 - np.sqrt(discriminant)) / (2 * beta_2)\n",
    "    predicted_days = max(predicted_days_1, predicted_days_2)\n",
    "    predicted_date = stream_stats['stream_date'].min() + pd.to_timedelta(predicted_days, unit='d')\n",
    "    print(f\"Expected to reach {target_hours} watch hours on: {predicted_date.date()}\")\n",
    "else:\n",
    "    print(\"No real solution found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2024 09 09\n",
    "\n",
    "Expected to reach 500 average viewers on: 2025-08-22 \\\n",
    "Expected to reach 300 active tier 1 & prime subs on: 2025-06-20 \\\n",
    "Expected to reach 5000000 watch hours on: 2030-12-02"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 34\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;66;03m# Try polynomial degrees 2 and 3 to find the best fit\u001b[39;00m\n\u001b[0;32m     33\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m degree \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m3\u001b[39m]:\n\u001b[1;32m---> 34\u001b[0m     r2, mse \u001b[38;5;241m=\u001b[39m \u001b[43mfit_polynomial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdegree\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     35\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDegree \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegree\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Polynomial: R² = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr2\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, MSE = \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmse\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.3f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m) \n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m cross_val_score\n",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m, in \u001b[0;36mfit_polynomial\u001b[1;34m(degree)\u001b[0m\n\u001b[0;32m     16\u001b[0m mse \u001b[38;5;241m=\u001b[39m mean_squared_error(y, y_pred)\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# Plot the polynomial regression curve\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[43mplt\u001b[49m\u001b[38;5;241m.\u001b[39mfigure(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m12\u001b[39m, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m     20\u001b[0m plt\u001b[38;5;241m.\u001b[39mscatter(X, y, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblue\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mData\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     21\u001b[0m plt\u001b[38;5;241m.\u001b[39mplot(X, y_pred, color\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mred\u001b[39m\u001b[38;5;124m'\u001b[39m, label\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mPolynomial Degree \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdegree\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "# Create a function to fit polynomial regression and evaluate performance\n",
    "def fit_polynomial(degree):\n",
    "    poly = PolynomialFeatures(degree=degree)\n",
    "    X_poly = poly.fit_transform(X)\n",
    "    \n",
    "    model = LinearRegression()\n",
    "    model.fit(X_poly, y)\n",
    "    \n",
    "    y_pred = model.predict(X_poly)\n",
    "    \n",
    "    # Calculate R² and MSE\n",
    "    r2 = r2_score(y, y_pred)\n",
    "    mse = mean_squared_error(y, y_pred)\n",
    "    \n",
    "    # Plot the polynomial regression curve\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.scatter(X, y, color='blue', label='Data')\n",
    "    plt.plot(X, y_pred, color='red', label=f'Polynomial Degree {degree}')\n",
    "    plt.axhline(y=500, color='green', linestyle='--', label='500 Viewers')\n",
    "    plt.legend()\n",
    "    plt.xlabel('Days Since First Stream')\n",
    "    plt.ylabel('Average Viewers')\n",
    "    plt.title(f'Degree {degree} Polynomial Fit (R²={r2:.3f}, MSE={mse:.3f})')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "    return r2, mse\n",
    "\n",
    "# Try polynomial degrees 2 and 3 to find the best fit\n",
    "for degree in [1, 2, 3]:\n",
    "    r2, mse = fit_polynomial(degree)\n",
    "    print(f'Degree {degree} Polynomial: R² = {r2:.3f}, MSE = {mse:.3f}') \n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "# Create a function to perform k-fold cross-validation for a given polynomial degree\n",
    "def cross_val_poly(degree):\n",
    "    model = make_pipeline(PolynomialFeatures(degree), LinearRegression())\n",
    "    \n",
    "    # Perform 5-fold cross-validation and get the average R² score\n",
    "    scores = cross_val_score(model, X, y, cv=5, scoring='r2')  # or scoring='neg_mean_squared_error'\n",
    "    return scores.mean()\n",
    "\n",
    "# Test for polynomial degrees 1 to 3\n",
    "for degree in range(1, 4):\n",
    "    avg_r2 = cross_val_poly(degree)\n",
    "    print(f'Degree {degree} Polynomial - Average R² from 5-Fold Cross-Validation: {avg_r2:.3f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
