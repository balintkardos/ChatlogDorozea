{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected to reach 500 average viewers on: 2025-05-21\n",
      "Expected to reach 300 active tier 1 & prime subs on: 2024-12-27\n",
      "Expected to reach 5000000 watch hours on: 2028-04-19\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Read the list of filenames from the configuration file\n",
    "with open('file_list.txt', 'r', encoding='utf-8') as config_file:\n",
    "    file_names = config_file.read().splitlines()\n",
    "\n",
    "# Regex pattern to match the data format\n",
    "pattern = r'\\[(.*?)\\] (.*?): (.*)'\n",
    "\n",
    "# Initialize an empty list to store parsed data\n",
    "datalist = []\n",
    "stream_count = 0\n",
    "\n",
    "# Parse each file\n",
    "for file in file_names:\n",
    "    full_path = f\"data\\\\{file}\"\n",
    "    with open(full_path, 'r', encoding='utf-8') as f:\n",
    "        lines = f.readlines()\n",
    "        for line in lines:\n",
    "            match = re.match(pattern, line)\n",
    "            if match:\n",
    "                date, user, message = match.groups()\n",
    "                datalist.append([date, user, message, stream_count])\n",
    "    stream_count += 1\n",
    "\n",
    "# Create a DataFrame from parsed data\n",
    "data = pd.DataFrame(datalist, columns=[\"date\", \"user\", \"message\", \"stream\"])\n",
    "data['date'] = pd.to_datetime(data['date'])\n",
    "data['first_message'] = data.groupby('user').cumcount().apply(lambda x: 1 if x == 0 else 0)\n",
    "\n",
    "# Calculate stream-level statistics\n",
    "stream_stats = data.groupby('stream').agg(\n",
    "    first_messages=('first_message', 'sum'),\n",
    "    total_messages=('stream', 'size'),\n",
    "    unique_chatters=('user', 'nunique')\n",
    ")\n",
    "\n",
    "# Calculate stream duration in seconds\n",
    "stream_stats['stream_length'] = data.groupby('stream')['date'].agg(lambda x: (x.max() - x.min()).total_seconds())\n",
    "stream_stats['stream_length_hour'] = stream_stats['stream_length'] / 3600\n",
    "\n",
    "# Load additional statistics from Excel\n",
    "exelStats = pd.read_excel('DorozeaStreamStats.xlsx', sheet_name='Munkalap1', header=None, names=['stream', 'avg', 'max', 'follow', 'games'], skiprows=1)\n",
    "\n",
    "# Merge stream statistics with Excel data\n",
    "stream_stats = pd.merge(stream_stats, exelStats, on='stream', how='right')\n",
    "stream_stats['hours_watched'] = stream_stats['stream_length_hour'] * stream_stats['avg']\n",
    "\n",
    "# Sub and gift data extraction\n",
    "subData = data[data.apply(lambda row: row['user'].lower() in row['message'].lower(), axis=1)]\n",
    "giftedData = subData[subData['message'].str.contains(' sub ', case=False, na=False)]\n",
    "\n",
    "# Calculate gifted subs and unique gifters per stream\n",
    "unique_gifters = giftedData.groupby('stream')['user'].nunique()\n",
    "stream_stats = pd.merge(stream_stats, unique_gifters.rename('gifters'), on='stream', how='left').fillna(0)\n",
    "\n",
    "gift_per_stream = giftedData.groupby('stream')['user'].count()\n",
    "stream_stats = pd.merge(stream_stats, gift_per_stream.rename('gift'), on='stream', how='left').fillna(0)\n",
    "\n",
    "# Calculate prime subs, and tier subs\n",
    "\n",
    "primeData = subData[subData['message'].str.contains('Prime', case=False, na=False)]\n",
    "prime_per_stream = primeData.groupby('stream')['user'].count()\n",
    "stream_stats = pd.merge(stream_stats, prime_per_stream.rename('prime'), on='stream', how='left').fillna(0)\n",
    "\n",
    "# Extract tier subs and calculate per stream\n",
    "trueSub = subData[~subData['message'].str.contains('Prime|raiders|gifting|gifted', case=False)]\n",
    "trueSub = trueSub[trueSub['message'].str.contains(' subscribed at ', case=False)]\n",
    "\n",
    "for tier in [1, 2, 3]:\n",
    "    tier_data = trueSub[trueSub['message'].str.contains(f'Tier {tier}', case=False)]\n",
    "    tier_per_stream = tier_data.groupby('stream')['user'].count()\n",
    "    stream_stats = pd.merge(stream_stats, tier_per_stream.rename(f'tier{tier}'), on='stream', how='left').fillna(0)\n",
    "\n",
    "# Add stream date information\n",
    "data['date_only'] = data['date'].dt.date\n",
    "stream_date = data.groupby('stream')['date_only'].min().reset_index().rename(columns={'date_only': 'stream_date'})\n",
    "stream_stats = pd.merge(stream_stats, stream_date, on='stream', how='left')\n",
    "stream_stats['stream_date'] = pd.to_datetime(stream_stats['stream_date'])\n",
    "\n",
    "# Calculate active subs, prime, and tiers in the last 30 days\n",
    "for col in ['tier1', 'prime', 'tier2', 'tier3', 'gift']:\n",
    "    active_col = f'active_{col}'\n",
    "    active_subs = []\n",
    "    for i in range(len(stream_stats)):\n",
    "        current_date = stream_stats.iloc[i]['stream_date']\n",
    "        mask = (stream_stats['stream_date'] <= current_date) & (stream_stats['stream_date'] > current_date - pd.Timedelta(days=30))\n",
    "        active_count = stream_stats.loc[mask, col].sum()\n",
    "        active_subs.append(active_count)\n",
    "    stream_stats[active_col] = active_subs\n",
    "\n",
    "# Total active subs calculation\n",
    "stream_stats['all_sub'] = stream_stats[['tier1', 'tier2', 'tier3', 'prime', 'gift']].sum(axis=1)\n",
    "\n",
    "# Cumulative watch hours\n",
    "initial_watch_hours = 97068\n",
    "stream_stats['watch_hour'] = stream_stats['hours_watched'].cumsum() + initial_watch_hours\n",
    "\n",
    "\n",
    "# Time since first stream\n",
    "stream_stats['days_since_first_stream'] = (stream_stats['stream_date'] - stream_stats['stream_date'].min()).dt.days\n",
    "\n",
    "\n",
    "# Linear regression to predict average viewers reaching 500\n",
    "X = stream_stats[['days_since_first_stream']]\n",
    "y = stream_stats['avg']\n",
    "model = LinearRegression().fit(X, y)\n",
    "target_viewers = 500\n",
    "predicted_days = (target_viewers - model.intercept_) / model.coef_[0]\n",
    "predicted_date = stream_stats['stream_date'].min() + pd.to_timedelta(predicted_days, unit='d')\n",
    "print(f\"Expected to reach {target_viewers} average viewers on: {predicted_date.date()}\")\n",
    "\n",
    "# Linear regression to predict 300 active subs (tier1 + prime)\n",
    "stream_stats_no_may = stream_stats[stream_stats['stream_date'] > '2024-05-31'].copy()\n",
    "X = stream_stats_no_may[['days_since_first_stream']]\n",
    "y = stream_stats_no_may['active_tier1'] + stream_stats_no_may['active_prime']\n",
    "model = LinearRegression().fit(X, y)\n",
    "target_active_subs = 300\n",
    "predicted_days = (target_active_subs - model.intercept_) / model.coef_[0]\n",
    "predicted_date = stream_stats_no_may['stream_date'].min() + pd.to_timedelta(predicted_days, unit='d')\n",
    "print(f\"Expected to reach {target_active_subs} active tier 1 & prime subs on: {predicted_date.date()}\")\n",
    "\n",
    "# Polynomial regression to predict 5M watch hours\n",
    "X = stream_stats[['days_since_first_stream']]\n",
    "y = stream_stats['watch_hour']\n",
    "poly = PolynomialFeatures(degree=2)\n",
    "X_poly = poly.fit_transform(X)\n",
    "model_poly = LinearRegression().fit(X_poly, y)\n",
    "\n",
    "# Solve quadratic equation for 5M watch hours\n",
    "target_hours = 5000000\n",
    "beta_0, beta_1, beta_2 = model_poly.intercept_, model_poly.coef_[1], model_poly.coef_[2]\n",
    "discriminant = beta_1**2 - 4*beta_2*(beta_0 - target_hours)\n",
    "\n",
    "if discriminant >= 0:\n",
    "    predicted_days_1 = (-beta_1 + np.sqrt(discriminant)) / (2 * beta_2)\n",
    "    predicted_days_2 = (-beta_1 - np.sqrt(discriminant)) / (2 * beta_2)\n",
    "    predicted_days = max(predicted_days_1, predicted_days_2)\n",
    "    predicted_date = stream_stats['stream_date'].min() + pd.to_timedelta(predicted_days, unit='d')\n",
    "    print(f\"Expected to reach {target_hours} watch hours on: {predicted_date.date()}\")\n",
    "else:\n",
    "    print(\"No real solution found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In 2024 09 09\n",
    "\n",
    "Expected to reach 500 average viewers on: 2025-08-22 \\\n",
    "Expected to reach 300 active tier 1 & prime subs on: 2025-06-20 \\\n",
    "Expected to reach 5000000 watch hours on: 2030-12-02"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
